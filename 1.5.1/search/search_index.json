{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#repid","title":"Repid","text":"<p> Repid framework: simple to use, fast to run and extensible to adopt job scheduler. </p> <p> </p>"},{"location":"#example","title":"Example","text":"<p>Here is how the easiest example of producer-consumer application can look like.</p> <p>Producer:</p> <pre><code>import asyncio\n\nfrom repid import Connection, Job, RabbitMessageBroker, Repid\n\napp = Repid(Connection(RabbitMessageBroker(\"amqp://user:password@localhost:5672\")))\n\n\nasync def main() -&gt; None:\n    async with app.magic():\n        await Job(name=\"awesome_job\").enqueue()\n\n\nasyncio.run(main())\n</code></pre> <p>Consumer:</p> <pre><code>import asyncio\n\nfrom repid import Connection, RabbitMessageBroker, Repid, Router, Worker\n\napp = Repid(Connection(RabbitMessageBroker(\"amqp://user:password@localhost:5672\")))\nrouter = Router()\n\n\n@router.actor\nasync def awesome_job() -&gt; None:\n    print(\"Hello async jobs!\")\n    await asyncio.sleep(1.0)\n\n\nasync def main() -&gt; None:\n    async with app.magic():\n        await Worker(routers=[router]).run()\n\n\nasyncio.run(main())\n</code></pre>"},{"location":"#install","title":"Install","text":"<p>Repid supports Python versions 3.8 and up and is installable via <code>pip</code>.</p> <pre><code>pip install repid\n</code></pre> <p>There are also a couple of additional dependencies you may want to install, depending on your use case, e.g.</p> <pre><code>pip install repid[amqp, redis, cron]\n</code></pre>"},{"location":"#why-repid","title":"Why repid?","text":""},{"location":"#asyncio","title":"Asyncio","text":"<p><code>Repid</code> is built around <code>asyncio</code>. It means it's pretty fast. And you don't have to worry that it will slow down your other asyncio-driven code.</p>"},{"location":"#ease-of-integration","title":"Ease of integration","text":"<p>There is an abstraction layer on top of other queue solutions. It means that even if <code>repid</code> doesn't provide some broker out of the box, you will be able to write your own.</p>"},{"location":"#built-with-microservices-in-mind","title":"Built with microservices in mind","text":"<p>Your producer and consumer can be running in different containers, <code>repid</code> will handle it just fine.</p>"},{"location":"#can-be-used-with-other-languages","title":"Can be used with other languages","text":"<p><code>Repid</code> uses json (de-)serialization by default, which makes integration with other languages as easy as possible. You're also able to easily override default (de-)serialization behavior thanks to PEP 544 Protocols.</p>"},{"location":"#integrated-scheduling","title":"Integrated scheduling","text":"<p><code>Repid</code> has its own scheduling mechanisms. You can delay job execution until some date or even execute it every once in a while. No need for extra dependencies!</p>"},{"location":"#inspiration","title":"Inspiration","text":"<p><code>Repid</code> is inspired by <code>dramatiq</code> and <code>arq</code>.</p>"},{"location":"#license","title":"License","text":"<p>Repid is distributed under the terms of the MIT license. Please see License.md for more information.</p> <p>Repid's logo is distributed under the terms of the CC BY-NC 4.0 license. It is originally created by ari_the_crow_.</p>"},{"location":"benchmarks/","title":"Benchmarks","text":"Disclaimer <p>The benchmarks documented in this section are intended to provide information on the performance of the software being tested under specific conditions. Never use benchmarks as the one and only decision maker.</p> <p>All results were conducted on the same machine, using 8 cores/16 threads processor. Top performers (Repid and Dramatiq with gevent) used up to 100% CPU resources, so it's likely that they can perform even better with higher end CPU. Obviously, absolute results will be different on different systems.</p> <p>You should always try to replicate benchmark results in your environment. For that purpose, please find <code>benchmarks</code> directory in the Repid repository.</p> <p>Finally, it is important to note that benchmarking is a complex process, results of which can be affected by various factors. Therefore, I encourage readers to write their own benchmarks for their exact purposes and run them in the appropriate environment.</p>"},{"location":"benchmarks/#considerations","title":"Considerations","text":"<p>The benchmark tests rate of processing I/O limited tasks. The task sleeps for 1 second (imitating I/O bound behavior, e.g. a very long running DB call) and then increments a Redis field, which is also used to monitor amount of processed tasks.</p> <p>Every library has been benchmarked 3 times and the results have been averaged.</p> <p>Due to very huge difference in speed between tested libraries, amount of messages was adjusted so that processing takes &gt; 10 seconds &amp; &lt; 3 minutes. Practically only values 800, 8000, 80000 were used.</p> <p>For celery &amp; dramatiq both \"green threads\" (eventlet &amp; gevent respectively) &amp; normal variants have been tested. One has to keep in mind that green threads in Python are doing monkey-patching, so one can face all sorts of weird behavior.</p> <p>Repid and arq are the only 2 libraries, which are able to take advantage of Python's asyncio.</p> <p>Every library uses RabbitMQ as a message broker, except arq, which only supports Redis.</p> <p>Repid uses uvloop to gain a bit more performance. I have tried using uvloop with arq as well, but faced inconsistent behavior, so I ended up disabling it.</p>"},{"location":"benchmarks/#credits","title":"Credits","text":"<p>Links to other tested libraries:</p> <ul> <li>dramatiq</li> <li>celery</li> <li>arq</li> </ul>"},{"location":"benchmarks/#the-charts","title":"The charts","text":"<p>Rates with green threads enabled for celery and dramatiq, in messages processed per second:</p> <p></p> <p>Rates without green threads, in messages processed per second:</p> <p></p>"},{"location":"contributing/","title":"Contributing to repid","text":"<p>Your contributions are invaluable to our community - thank you for being a part of the journey!</p>"},{"location":"contributing/#development-setup","title":"Development setup","text":""},{"location":"contributing/#quick-overview","title":"Quick overview","text":"<ol> <li>Create a fork of repid</li> <li>Clone your fork</li> <li>Install PDM</li> <li>Install dependencies in virtual environment</li> <li>Configure pre-commit</li> <li>Make your changes!</li> </ol>"},{"location":"contributing/#detailed-guide","title":"Detailed guide","text":""},{"location":"contributing/#create-a-fork-and-clone-the-repo","title":"Create a fork and clone the repo","text":"<p>First of all, you will need to create a fork.</p> <p>Clone it and <code>cd</code> into the directory:</p> <pre><code>git clone https://github.com/__your_username__/repid.git\ncd repid\n</code></pre>"},{"location":"contributing/#pdm-venv","title":"PDM &amp; venv","text":"<p>Repid uses PDM to manage virtual environment, dependencies &amp; package the project.</p> <p>Tip</p> <p>Use <code>brew</code> or <code>pipx</code> when installing PDM to keep your system Python clean.</p> <pre><code>brew install pdm\n</code></pre> <pre><code>pipx install pdm\n</code></pre> <p>After installation is done, run the following command in the project's root directory:</p> <pre><code>pdm install --group :all\n</code></pre> <p>It will create virtual environment and install inside of it all dependencies, including those, which are needed for development.</p> <p>Important</p> <p>Use lowest supported by <code>repid</code> version of Python (== 3.8 for now) for your venv.</p> <p>You can use pyenv to set up multiple versions of Python on your system.</p> <p>To activate a venv run:</p> <pre><code>$(pdm venv activate)\n</code></pre> <p>...or simply execute the needed command with <code>pdm run</code> prefix, e.g.</p> <pre><code>pdm run mkdocs serve\n</code></pre>"},{"location":"contributing/#pre-commit","title":"pre-commit","text":"<p><code>repid</code> uses pre-commit to run linters and formatters. To initialize <code>pre-commit</code> run:</p> <pre><code>pdm run pre-commit install --install-hooks\n</code></pre> <p>If you want to run all linters and formatters, execute the following command:</p> <pre><code>pdm run pre-commit run -a\n</code></pre> <p>If you want to commit some changes disregarding pre-commit hooks, add <code>-n</code> or <code>--no-verify</code> flag to <code>git commit</code> command.</p> <p>Important</p> <p>Keep in mind that when you will submit your pull request, all the hooks must pass in CI anyway, or, unfortunately, we will have to decline your contribution.</p>"},{"location":"contributing/#make-your-changes","title":"Make your changes","text":"<p>Make your changes, create commits and submit a pull request.</p> <p>Here are some advices:</p> <ol> <li> <p>Commits:</p> <ul> <li>Please use gitmoji to prefix your commit messages</li> <li>Try to make commits atomic</li> <li>gitmoji should describe type of the change, while commit message shows the exact change in behavior, e.g.</li> </ul> <pre><code>\u267b\ufe0f Refactored _signal_emitter property and wrapping in new into a separate _WrapperABC class\n</code></pre> </li> <li> <p>Issues:</p> <ul> <li>Please use one of provided templates to create an issue</li> <li>Make it as much descriptive as possible</li> </ul> </li> <li> <p>Pull requests:</p> <ul> <li>If your pull request isn't very simple (like fixing a typo in the docs) - please create an issue first, so we can discuss it</li> <li>Mark pull request as a resolver for the related issue(-s)</li> <li>Please complete the checklist provided in the pull request template</li> <li>Please avoid creating very large pull requests</li> </ul> </li> </ol>"},{"location":"contributing/#running-tests-locally","title":"Running tests locally","text":"<p>You will need docker to run tests locally.</p> <p>Apart from that, everything is automated via pytest (including creation of containers for integration testing!), so all you need to do is:</p> <pre><code>pdm run pytest\n</code></pre> <p>If you want to run test suite with all default arguments already set up - there is a PDM script:</p> <pre><code>pdm run test\n</code></pre>"},{"location":"contributing/#vscode-and-dev-container","title":"VSCode and Dev Container","text":"<p>If you are willing to use VSCode, repid comes with some configs already in place. Feel free to modify them up to your liking, but be careful not to commit any changes unintentionally.</p> <p>Another quality-of-life feature is Dev Container. Essentially it is a bunch of configs, which describe how to create a docker container, that comes with VSCode server, all the necessary plugins and a virtual environment already set up. You can use it with GitHub Codespaces to create it in one click and start developing right away!</p>"},{"location":"features/","title":"Features","text":""},{"location":"features/#message-protocols-abstraction","title":"Message protocols abstraction","text":"<p>One of the key features of Repid is its message protocols abstraction layer, which allows developers to work with message brokers without worrying about the underlying implementation details. Not only this makes it easy for developers to quickly create applications that use various message brokers to communicate with other systems and services, but it also ensures ease of integration with those brokers, which are not supported out-of-the-box.</p>"},{"location":"features/#application-level-routing","title":"Application level routing","text":"<p>Repid provides a robust application level routing system that allows developers to easily define and handle different routes within their application. This allows developers to build complex applications that can route different requests, even if they are coming from one queue. You don't have to rely on broker to support routing anymore!</p>"},{"location":"features/#asyncio-top-to-bottom","title":"asyncio top-to-bottom","text":"<p>Another key feature of Repid is that it uses asyncio everywhere: from broker level to execution of your function. This allows developers to build highly concurrent applications that can take advantage of the performance benefits of asyncio. But don't worry - synchronous code is still possible to run!</p>"},{"location":"features/#flexible","title":"Flexible","text":"<p>Repid provides you with sensible defaults, but it's okay to disagree! The framework allows you to change some of it's core functions, such as data structures (and their encoding/decoding mechanisms), function argument mapper and validator, input serializer and more.</p>"},{"location":"features/#middlewares","title":"Middlewares","text":"<p>Repid includes support for middlewares, which are functions that can be used to extend the functionality of an application. You can use middlewares to add, for example, custom logging to your application.</p>"},{"location":"playground/","title":"Playground","text":"<p>   packages = [\"repid\"] </p> Info <p>This is a playground where you can edit and run code in your browser using PyScript - give it a try, it's awesome!</p> Edit me!<pre><code>async def main() -&gt; None:\n    import repid\n\n    app = repid.Repid(repid.Connection(repid.InMemoryMessageBroker()))\n\n    router = repid.Router()\n\n    @router.actor\n    async def string_length(the_string: str) -&gt; int:\n        print(the_string)\n        await asyncio.sleep(1)\n        print(\"I've slept well...\")\n        return len(the_string)\n\n    async with app.magic():\n        hello_job = repid.Job(\n            \"string_length\",\n            args=dict(the_string=\"Hello world!\"),\n        )\n        await hello_job.queue.declare()\n        await hello_job.enqueue()\n        worker = repid.Worker(routers=[router], messages_limit=1, handle_signals=[])\n        await worker.run()\n</code></pre> <p>     import asyncio     from pyscript import Element     from html.parser import HTMLParser     def eval_python():         class HTMLFilter(HTMLParser):             text = \"\"             def handle_data(self, data):                 self.text += data         f = HTMLFilter()         input_html = Element(\"input\").innerHtml         input_html = input_html.replace(\"\", \"\\n\")  # user inputted new lines == \"\"         f.feed(input_html)         f.text = f.text[10:]  # remove \"Edit me!\"         locals = {}         exec(f.text, globals(), locals)         asyncio.create_task(locals.get(\"main\")()) </p> <p>Run main()!</p> <p>Your output will be here:</p> <p></p>"},{"location":"quickstart_guide/","title":"Quickstart Guide","text":""},{"location":"quickstart_guide/#before-we-start","title":"Before we start","text":"<p>To follow this guide you will need a virtual environment with <code>repid</code> installed. We will use in memory brokers, but feel free to exchange those for any other ones - it should just work.</p>"},{"location":"quickstart_guide/#consumer","title":"Consumer","text":"<p>Let's start by creating a simple pseudo-async function that counts length of a string:</p> <pre><code>import asyncio\n\n\nasync def string_length(the_string: str) -&gt; int:\n    await asyncio.sleep(1)\n    print(the_string)\n    return len(the_string)\n</code></pre> <p>Now, we have to create a router for <code>repid</code> to know, that <code>string_length</code> actor exists.</p> <pre><code>import asyncio\n\nimport repid\n\nrouter = repid.Router()\n\n\n@router.actor\nasync def string_length(the_string: str) -&gt; int:\n    await asyncio.sleep(1)\n    print(the_string)\n    return len(the_string)\n</code></pre> <p>Aaand let's finish our application with specifying connection and creating a worker.</p> <pre><code>import asyncio\n\nimport repid\n\napp = repid.Repid(repid.Connection(repid.InMemoryMessageBroker()))  # (1)\n\nrouter = repid.Router()\n\n\n@router.actor\nasync def string_length(the_string: str) -&gt; int:\n    await asyncio.sleep(1)\n    print(the_string)\n    return len(the_string)\n\n\nasync def main() -&gt; None:  # (2)\n    async with app.magic():  # (3)\n        worker = repid.Worker(routers=[router])  # (4)\n        await worker.run()  # (5)\n\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre> <ol> <li>Create a <code>repid</code> app with the in-memory message broker.</li> <li>The main function, which will execute our async code.</li> <li>Inside of this context manager every object will be provided with the connection that is attached to the <code>repid</code> app which we've created.</li> <li>Create an instance of a worker. Don't forget to specify our router!</li> <li>Run the worker until it receives a <code>SIGINT</code> ( Ctrl+C ) or a <code>SIGTERM</code>.</li> </ol>"},{"location":"quickstart_guide/#producer","title":"Producer","text":"<p>Let's enqueue a job!</p> example.py<pre><code>import asyncio\n\nimport repid\n\napp = repid.Repid(repid.Connection(repid.InMemoryMessageBroker()))\n\nrouter = repid.Router()\n\n\n@router.actor\nasync def string_length(the_string: str) -&gt; int:\n    await asyncio.sleep(1)\n    print(the_string)\n    return len(the_string)\n\n\nasync def main() -&gt; None:\n    async with app.magic():\n        hello_job = repid.Job(\n            \"string_length\",  # (1)\n            args=dict(the_string=\"Hello world!\"),  # (2)\n        )\n        await hello_job.queue.declare()  # (3)\n        await hello_job.enqueue()\n        worker = repid.Worker(routers=[router])\n        await worker.run()\n\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre> <ol> <li>Name of the job will be used to route it to the similarly named actor.</li> <li>Using dictionary to map arguments' names to values. The dictionary will be encoded with <code>json</code> module by default.</li> <li>You only need to declare a queue once. Ideally you would do that on application startup.</li> </ol> <p>This will enqueue a job to the default queue, which than worker will consume &amp; route to the <code>string_length</code> function with argument <code>the_string</code> set to <code>\"Hello world!\"</code>.</p> <p>After running the script, you should receive:</p> <pre><code>$ python example.py\n\nHello world!\n</code></pre>"},{"location":"advanced_user_guide/configuring_overrides/","title":"Configuring overrides","text":"<p>Coming soon! Help us write documentation by submitting a  pull request! Also check out contributing guide!</p>"},{"location":"advanced_user_guide/health_checks/","title":"Health checks","text":"<p>Repid comes with builtin HTTP server to provide you ability to make health checks.</p> <p>To enable it, simply set <code>run_health_check_server</code> to True when creating your Worker.</p> <pre><code>from repid import Worker\n\n# code above is omitted\n\nmyworker = Worker(\n    run_health_check_server=True,\n)\n\n# code below is omitted\n</code></pre> <p>The health check server will then be started when you run your Worker.</p> <pre><code># health check server is not yet started\n\nawait myworker.run()  # health check server runs as long as Worker runs\n\n# health check server is shut down\n</code></pre> <p>By default the server will be launched with address <code>0.0.0.0</code> on port <code>8080</code>, default endpoint is <code>/healthz</code>. You can override those parameters with settings.</p> <pre><code>from repid import Worker, HealthCheckServerSettings\n\n# code above is omitted\n\nmyworker = Worker(\n    run_health_check_server=True,\n    health_check_server_settings=HealthCheckServerSettings(\n        address=\"127.0.0.1\",\n        port=\"12345\",\n        endpoint_name=\"/health-check\",\n    ),\n)\n\n# code below is omitted\n</code></pre>"},{"location":"advanced_user_guide/middlewares/","title":"Middlewares","text":"<p>Compatibility</p> <p>Middlewares are a subject to change, as those are representing internal functions.</p> <p>They don't follow semantic versioning and can introduce breaking changes in minor versions. Patch versions, on the other hand, are guaranteed to not to introduce any breaking changes.</p> <p>Any breaking changes will be mentioned in release notes.</p> <p>Some of Repid functions are wrapped to emit events before and after its execution. You can subscribe to those events with your own middlewares.</p> <p>To create a middleware, you can either use class-based or function-based approach.</p>"},{"location":"advanced_user_guide/middlewares/#class-based","title":"Class-based","text":"<p>For example, let's create a middleware which will report errors to Sentry.</p> <pre><code>import os\nimport sentry_sdk\nfrom repid import Repid, Connection, InMemoryMessageBroker\nfrom repid.actor import ActorResult\n\napp = Repid(Connection(InMemoryMessageBroker()))  # (1)\n\n\nclass SentryMiddleware:\n    def __init__(self, sentry_dsn: str) -&gt; None:\n        sentry_sdk.init(dsn=sentry_dsn)\n\n    def after_actor_run(self, result: ActorResult) -&gt; None:  # (2)\n        if not result.success:\n            sentry_sdk.capture_exception(result.exception)  # (3)\n\n\nsentry_middleware_instance = SentryMiddleware(os.environ.get(\"SENTRY_DSN\"))  # (4)\n\napp.connection.middleware.add_middleware(sentry_middleware_instance)  # (5)\n</code></pre> <ol> <li>Create a Repid app and a Connection as you normally would</li> <li>Create a specifically named method, which will receive specifically named arguments</li> <li>Report exceptions to Sentry</li> <li>Initialize the middleware</li> <li>Pass middleware to Repid's connection</li> </ol>"},{"location":"advanced_user_guide/middlewares/#function-based","title":"Function-based","text":"<p>Let's replicate the example above using function-based approach.</p> <pre><code>import os\nimport sentry_sdk\nfrom repid import Repid, Connection, InMemoryMessageBroker\nfrom repid.actor import ActorResult\n\napp = Repid(Connection(InMemoryMessageBroker()))  # (1)\n\nsentry_sdk.init(dsn=os.environ.get(\"SENTRY_DSN\"))\n\n\ndef after_actor_run(result: ActorResult) -&gt; None:  # (2)\n    if not result.success:\n        sentry_sdk.capture_exception(result.exception)  # (3)\n\n\napp.connection.middleware.add_subscriber(after_actor_run)  # (4)\n</code></pre> <ol> <li>Create a Repid app and a Connection as you normally would</li> <li>Create a specifically named function, which will receive specifically named arguments</li> <li>Report exceptions to Sentry</li> <li>Subscribe the function to the appropriate event</li> </ol>"},{"location":"advanced_user_guide/middlewares/#naming-convention-arguments-async","title":"Naming convention, arguments, async","text":"<p>Only functions named accordingly to emitted events (see glossary below) will be executed.</p> <p>You can optionally include any of the suggested arguments. Only included arguments will be passed to the subscriber. The \"after_\" functions also contain a special argument <code>result</code>, which represents the return of the function emitting the signal.</p> <p>You can use both asynchronous &amp; synchronous functions. The latter will be executed in threads to not to block async loop.</p>"},{"location":"advanced_user_guide/middlewares/#events-glossary","title":"Events glossary","text":"<p>Here is the full list of events, their arguments and type hints, which you can subscribe to.</p>"},{"location":"advanced_user_guide/middlewares/#consume","title":"Consume","text":"<ul> <li><code>before_consume()</code></li> <li><code>after_consume(result: tuple[RoutingKeyT, EncodedPayloadT, ParametersT])</code></li> </ul>"},{"location":"advanced_user_guide/middlewares/#enqueue","title":"Enqueue","text":"<ul> <li><code>before_enqueue(key: RoutingKeyT, payload: EncodedPayloadT, params: ParametersT | None)</code></li> <li><code>after_enqueue(key: RoutingKeyT, payload: EncodedPayloadT,params: ParametersT | None, result: None)</code></li> </ul>"},{"location":"advanced_user_guide/middlewares/#queue-declare","title":"Queue Declare","text":"<ul> <li><code>before_queue_declare(queue_name: str)</code></li> <li><code>after_queue_declare(queue_name: str, result: None)</code></li> </ul>"},{"location":"advanced_user_guide/middlewares/#queue-flush","title":"Queue Flush","text":"<ul> <li><code>before_queue_flush(queue_name: str)</code></li> <li><code>after_queue_flush(queue_name: str, result: None)</code></li> </ul>"},{"location":"advanced_user_guide/middlewares/#queue-delete","title":"Queue Delete","text":"<ul> <li><code>before_queue_delete(queue_name: str)</code></li> <li><code>after_queue_delete(queue_name: str, result: None)</code></li> </ul>"},{"location":"advanced_user_guide/middlewares/#ack","title":"Ack","text":"<ul> <li><code>before_ack(key: RoutingKeyT)</code></li> <li><code>after_ack(key: RoutingKeyT, result: None)</code></li> </ul>"},{"location":"advanced_user_guide/middlewares/#nack","title":"Nack","text":"<ul> <li><code>before_nack(key: RoutingKeyT)</code></li> <li><code>after_nack(key: RoutingKeyT, result: None)</code></li> </ul>"},{"location":"advanced_user_guide/middlewares/#reject","title":"Reject","text":"<ul> <li><code>before_reject(key: RoutingKeyT)</code></li> <li><code>after_reject(key: RoutingKeyT, result: None)</code></li> </ul>"},{"location":"advanced_user_guide/middlewares/#requeue","title":"Requeue","text":"<ul> <li><code>before_requeue(key: RoutingKeyT, payload: str, params: ParametersT | None)</code></li> <li><code>after_requeue(key: RoutingKeyT, payload: str, params: ParametersT | None, result: None)</code></li> </ul>"},{"location":"advanced_user_guide/middlewares/#get-bucket","title":"Get Bucket","text":"<ul> <li><code>before_get_bucket(id_: str)</code></li> <li><code>after_get_bucket(id_: str, result: BucketT | None)</code></li> </ul>"},{"location":"advanced_user_guide/middlewares/#store-bucket","title":"Store Bucket","text":"<ul> <li><code>before_store_bucket(id_: str, payload: BucketT)</code></li> <li><code>after_store_bucket(id_: str, payload: BucketT, result: None)</code></li> </ul>"},{"location":"advanced_user_guide/middlewares/#delete-bucket","title":"Delete Bucket","text":"<ul> <li><code>before_delete_bucket(id_: str)</code></li> <li><code>after_delete_bucket(id_: str, result: None)</code></li> </ul>"},{"location":"advanced_user_guide/middlewares/#actor-run","title":"Actor Run","text":"<ul> <li><code>before_actor_run(actor: ActorData, key: RoutingKeyT, parameters: ParametersT,payload: str)</code></li> <li><code>after_actor_run(actor: ActorData, key: RoutingKeyT, parameters: ParametersT,payload: str, result: ActorResult)</code></li> </ul>"},{"location":"advanced_user_guide/validating_with_pydantic/","title":"Validating with Pydantic","text":"<p>Repid provides you with Pydantic validation out-of-the box. Here you will find details on how to use it.</p>"},{"location":"advanced_user_guide/validating_with_pydantic/#prerequisite","title":"Prerequisite","text":"<p>Repid will only enable Pydantic validation if Pydantic itself is installed.</p> <p>To ensure correct installation of a supported version you can run:</p> <pre><code>pip install repid[pydantic]\n</code></pre> <p>Currently official support is targeting Pydantic v2, while option to go with v1 is also being provided, however v1 is not being included in the test suite.</p>"},{"location":"advanced_user_guide/validating_with_pydantic/#submitting-arguments-to-a-job","title":"Submitting arguments to a Job","text":"<p>Repid's default serializer supports Pydantic models, so you can specify them as your Job args.</p> <pre><code>from repid import Router, Job\nfrom pydantic import BaseModel\n\nclass MyPydanticModel(BaseModel):\n    user_id: int\n    actions: list[str]\n\n# connection code is omitted\nJob(\n    \"some_repid_actor\",\n    args=MyPydanticModel(\n        user_id=123,\n        actions=[\"First action\"],\n    ),\n)\n</code></pre> <p>You can also use Pydantic models inside of another structures (such as dictionaries, dataclasses, etc.) - Repid's JSON encoder will automatically convert Pydantic models using <code>.model_dump(mode=\"json\")</code>.</p> <pre><code>Job(\n    \"some_another_repid_actor\",\n    args={\n        \"body\": MyPydanticModel(\n            user_id=123,\n            actions=[\"First action\"],\n        ),\n    },\n)\n</code></pre>"},{"location":"advanced_user_guide/validating_with_pydantic/#validating-actor-input","title":"Validating Actor input","text":"<p>When running in environment with Pydantic v1 or v2, Repid will automatically prefer to select appropriate converter.</p> With Pydantic installedWithout Pydantic installed <pre><code>from repid import DefaultConverter, BasicConverter, PydanticConverter\n\ndef myfunc(a: int, b: str) -&gt; str:\n    return str(a) + b\n\nc = DefaultConverter(myfunc)  # (1)\n\nassert type(c) is BasicConverter  # False\nassert type(c) is PydanticConverter  # True\n</code></pre> <ol> <li><code>DefaultConverter</code> is just a proxy to create <code>PydanticConverter</code> when Pydantic is installed and <code>BasicConverter</code> otherwise.</li> </ol> <pre><code>from repid import DefaultConverter, BasicConverter, PydanticConverter\n\ndef myfunc(a: int, b: str) -&gt; str:\n    return str(a) + b\n\nc = DefaultConverter(myfunc)  # (1)\n\nassert type(c) is BasicConverter  # True\nassert type(c) is PydanticConverter  # False\n</code></pre> <ol> <li><code>DefaultConverter</code> is just a proxy to create <code>PydanticConverter</code> when Pydantic is installed and <code>BasicConverter</code> otherwise.</li> </ol> <p>Considering you have <code>PydanticConverter</code> enabled - all you need to do is create an actor with type hinted arguments.</p> <pre><code>from repid import Router\n\nmy_router = Router()\n\n@my_router.actor\nasync def some_repid_actor(user_id: int, actions: list[str]) -&gt; None:\n    ...\n</code></pre> <p>Those type hints will then be used to create a Pydantic model in the converter, so that it can validate/transform your arguments, ensuring that your actor will receive data in the expected format.</p> <p>You can also assign defaults and <code>pydantic.Field</code> to an argument, e.g. to create an alias.</p> <pre><code>from repid import Router\nfrom pydantic import Field\n\nmy_router = Router()\n\n@my_router.actor\nasync def some_repid_actor(\n    user_id: int = 123,\n    actions: list[str] = Field(alias=\"activity\"),\n) -&gt; None:\n    ...\n</code></pre>"},{"location":"advanced_user_guide/validating_with_pydantic/#validating-actor-outputs","title":"Validating Actor outputs","text":"<p>If you have Pydantic installed and you have specified return type annotation (any, other than <code>None</code>) - your data will be validated with Pydantic.</p> <pre><code>import asyncio\nfrom repid import Router\nfrom pydantic import BaseModel\n\n\nclass MyReturnModel(BaseModel):\n    user_id: int\n\nmy_router = Router()\n\n@my_router.actor\nasync def some_repid_actor(\n    user_id: int,\n    actions: list[str],\n) -&gt; MyReturnModel:\n    return dict(user_id=user_id, actions=actions)\n\n\n# connection code is omitted\nj = Job(\n    \"some_repid_actor\",\n    args=dict(user_id=123, actions=[\"First action\"]),\n)\nawait j.enqueue()\nawait asyncio.sleep(0.1)\nassert (await j.result).data == dict(user_id=123)  # True\n</code></pre> <p>In this example we can see how Pydantic validation can be useful to protect sensitive info to be passed outside of the Actor - result only contains contents, specified in the <code>MyReturnModel</code>.</p>"},{"location":"advanced_user_guide/validating_with_pydantic/#disabling-pydantic-converter","title":"Disabling Pydantic Converter","text":"<p>To disable Pydantic converter, simply set Config to use BasicConverter.</p> <pre><code>from repid import Config, BasicConverter\n\nConfig.CONVERTER = BasicConverter\n</code></pre>"},{"location":"advanced_user_guide/your_own_brokers/","title":"Your own brokers","text":"<p>Coming soon! Help us write documentation by submitting a  pull request! Also check out contributing guide!</p>"},{"location":"advanced_user_guide/your_own_converter/","title":"Your own converter","text":"<p>Coming soon! Help us write documentation by submitting a  pull request! Also check out contributing guide!</p>"},{"location":"advanced_user_guide/your_own_data_models/","title":"Your own data models","text":"<p>Coming soon! Help us write documentation by submitting a  pull request! Also check out contributing guide!</p>"},{"location":"advanced_user_guide/your_own_serializer/","title":"Your own serializer","text":"<p>Coming soon! Help us write documentation by submitting a  pull request! Also check out contributing guide!</p>"},{"location":"cookbook/chaining_jobs/","title":"Chaining jobs","text":"<p>You can chain jobs using eager response and callback. You can find more details about those in the user guide.</p> <p>We will also take advantage of result bucket technically being a superset of the arguments bucket, which allows us to pass result of one job as arguments to another one.</p> <p>That is, if simplified, it looks as follows:</p> <pre><code>Job(\"job1\", result_id=\"my_chained_id\")  # (1)\nJob(\"job2\", args_id=\"my_chained_id\")\n</code></pre> <ol> <li>Result bucket id corresponds to the second job's arguments bucket id</li> </ol> <p>Now, let's imagine you were designing some pipeline of jobs. The first one would construct some sort of a greetings message and pass it to the second job. The second job will append to the greetings message some information about user's id.</p> <pre><code>import asyncio\nimport os\n\nfrom repid import (\n    Connection,\n    Job,\n    MessageDependency,\n    RedisBucketBroker,\n    RedisMessageBroker,\n    Repid,\n    Router,\n    Worker,\n)\n\nredis_messages_dsn = os.environ.get(\"REDIS_CONNECTION\")\nredis_args_and_results_dsn = os.environ.get(\"REDIS_ARGS_CONNECTION\")\n\nmy_connection = Connection(\n    message_broker=RedisMessageBroker(redis_messages_dsn),\n    args_bucket_broker=RedisBucketBroker(redis_args_and_results_dsn),\n    results_bucket_broker=RedisBucketBroker(\n        redis_args_and_results_dsn,\n        use_result_bucket=True,\n    ),\n)\n\napp = Repid(my_connection)\n\nmy_router = Router()\n\n\n@my_router.actor\nasync def add_hello(msg: MessageDependency, user_name: str, user_id: int) -&gt; dict:\n    msg.set_result(dict(user_id=user_id, greetings=f\"Hello {user_name}!\"))\n\n    j = Job(\"add_id\", args_id=msg.parameters.result.id_, result_id=\"some_result_id\")\n    msg.add_callback(j.enqueue)\n\n    await msg.ack()\n\n\n@my_router.actor\nasync def add_id(user_id: int, greetings: str) -&gt; str:\n    return f\"{greetings} Your id is {user_id}.\"\n\n\nasync def main() -&gt; None:\n    async with app.magic(auto_disconnect=True):\n        w = Worker(routers=[my_router], messages_limit=2)\n\n        await Job(\n            \"add_hello\",\n            args=dict(user_name=\"Alex\", user_id=123),\n            result_id=\"chained_id\",\n        ).enqueue()\n\n        await w.run()\n\n        result_bucket = await Job(\"add_id\", result_id=\"some_result_id\").result\n        print(result_bucket.data)  # (1)\n\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre> <ol> <li>Prints <code>Hello Alex! Your id is 123.</code></li> </ol>"},{"location":"cookbook/fastapi_and_pydantic/","title":"FastAPI and Pydantic","text":"<p>Here is how to use Repid with FastAPI and Pydantic.</p>"},{"location":"cookbook/fastapi_and_pydantic/#fastapi-lifespan-to-open-and-close-repids-connection","title":"FastAPI lifespan to open and close Repid's connection","text":"<p>You can use FastAPI lifespan events with Repid's magic connection mechanism.</p> <pre><code>from contextlib import asynccontextmanager\n\nfrom fastapi import FastAPI\nfrom repid import Repid, Connection, InMemoryMessageBroker, Job\n\nrepid_app = Repid(Connection(InMemoryMessageBroker()))\n\n\n@asynccontextmanager\nasync def lifespan(app: FastAPI):\n    async with repid_app.magic(auto_disconnect=True):\n        yield\n\n\napp = FastAPI(lifespan=lifespan)\n\n\n@app.post(\"/create-repid-job\")\nasync def create_repid_job() -&gt; str:\n    routing_key, _, _ = await Job(\"some_job\").enqueue()\n    return routing_key.id_\n</code></pre>"},{"location":"cookbook/fastapi_and_pydantic/#pydantic-models-as-job-arguments","title":"Pydantic models as job arguments","text":"<p>You can pass Pydantic models to Repid's default serializer.</p> <pre><code>from repid import Router, Job\nfrom pydantic import BaseModel\n\nclass MyPydanticModel(BaseModel):\n    user_id: int\n    actions: list[str]\n\n\nmy_router = Router()\n\n@my_router.actor\nasync def some_repid_actor(user_id: int, actions: list[str]) -&gt; None:\n    await do_something()\n\n\n# Connection code omitted\nawait Job(\n    \"some_repid_actor\",\n    args=MyPydanticModel(user_id=123, actions=[\"First action\"]),\n).enqueue()\n</code></pre>"},{"location":"cookbook/reschedule_dead_messages/","title":"Reschedule dead messages","text":"<p>Let's say for some reason you have messages in dead queue, which you want to reschedule (i.e. try again). You can do it as follows:</p> <pre><code>import asyncio\n\nfrom repid import Repid, Queue, MessageCategory\n\n\napp = Repid(my_connection)  # (1)\n\n\nasync def main() -&gt; None:\n    async with app.magic(auto_disconnect=True):\n        q = Queue(name=\"my_queue\")\n\n        async for msg in q.get_messages(category=MessageCategory.DEAD):  # (2)\n            await msg.reschedule()\n\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre> <ol> <li>Connection setup is omitted</li> <li>Will run indefinetly, you can exit with Ctrl+C</li> </ol> <p>Alternativly, you can use <code>anext</code> and exit when you don't receive message for some time.</p> Python 3.10+Python 3.8+ <pre><code>import asyncio\n\nfrom repid import Repid, Queue, MessageCategory\n\nEXIT_AFTER = 10  # seconds\n\n\napp = Repid(my_connection)  # (1)\n\n\nasync def main() -&gt; None:\n    async with app.magic(auto_disconnect=True):\n        q = Queue(name=\"my_queue\")\n\n        iterator = q.get_messages(category=MessageCategory.DEAD)\n\n        while True:\n            try:\n                msg = await asyncio.wait_for(anext(iterator), timeout=EXIT_AFTER)  # (2)\n            except asyncio.TimeoutError:\n                break\n\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre> <ol> <li>Connection setup is omitted</li> <li>Will raise an exception after specified amount of seconds, thus exiting the loop</li> </ol> <pre><code>import asyncio\n\nfrom repid import Repid, Queue, MessageCategory\n\nEXIT_AFTER = 10  # seconds\n\n\napp = Repid(my_connection)  # (1)\n\n\nasync def main() -&gt; None:\n    async with app.magic(auto_disconnect=True):\n        q = Queue(name=\"my_queue\")\n\n        iterator = q.get_messages(category=MessageCategory.DEAD)\n\n        while True:\n            try:\n                msg = await asyncio.wait_for(iterator.__anext__(), timeout=EXIT_AFTER)  # (2)\n            except asyncio.TimeoutError:\n                break\n\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre> <ol> <li>Connection setup is omitted</li> <li>Will raise an exception after specified amount of seconds, thus exiting the loop</li> </ol>"},{"location":"user_guide/arguments_and_results/","title":"Arguments &amp; Results","text":"<p>Repid provides mechanisms to pass arguments to a job and retrieve the job's result.</p>"},{"location":"user_guide/arguments_and_results/#preparation","title":"Preparation","text":"<p>First of all, you will have to define what will be used to store the data. Arguments can either be stored inside of a message (so you only need message broker) or inside of a bucket broker. Results, on the other hand, can only be stored in a result bucket broker.</p> <p>For example, let's create a connection with InMemoryBucketBroker.</p> <pre><code>from repid import Connection, InMemoryMessageBroker, InMemoryBucketBroker\n\nmy_connection = Connection(\n    message_broker=InMemoryMessageBroker(),\n    args_bucket_broker=InMemoryBucketBroker(),\n    results_bucket_broker=InMemoryBucketBroker(,\n        use_result_bucket=True,\n    ),\n)\n</code></pre> <p>We can then experiment with storing of our buckets.</p>"},{"location":"user_guide/arguments_and_results/#arguments","title":"Arguments","text":"<p>First of all, let's create an actor with some arguments.</p> <pre><code>from repid import Router\n\nrouter = Router()\n\n\n@router.actor\nasync def actor_with_args(user_id: int, user_name: str, user_messages: list[str]) -&gt; list[str]:\n    user_message = f\"Hi {user_name}! Your id is: {user_id}.\"\n    user_messages.append(user_message)\n    return user_messages\n</code></pre> <p>Now we would like to schedule a job, which will pass those arguments to the actor.</p> <pre><code>from repid import Job\n\n# code above is omitted\n\nawait Job(\n    \"actor_with_args\",\n    args=dict(user_id=123, user_name=\"Alex\", user_messages=[\"This is your first message!\"]),\n).enqueue()\n\n# code below is omitted\n</code></pre> <p>What will happen under the hood?</p> <ol> <li><code>Job.args</code> will be serialized using <code>Config.SERIALIZER</code></li> <li>The serialized string will be<ul> <li>encoded into the message or</li> <li>passed to arguments bucket broker if <code>Job.use_args_bucketer</code> is set to True<ul> <li>defaults to True if the current connection contains arguments bucket broker</li> </ul> </li> </ul> </li> <li>When the message will be received by the actor, arguments will be decoded and mapped to the function arguments using actor's <code>Converter.convert_inputs</code></li> <li>The return of the actor will be encoded using actor's <code>Converter.convert_outputs</code></li> </ol>"},{"location":"user_guide/arguments_and_results/#results","title":"Results","text":"<p>You can define whether to store result of a job or not using <code>Job.store_result</code> argument.</p> <pre><code>Job(\"some_job\", store_result=True)\n</code></pre> <p>The default is to store result, if connection contains result bucket broker, and not to store result otherwise.</p> <p>You can access result of a job using <code>Job.result</code> async property.</p> <pre><code>import asyncio\nfrom repid import Job\n\n# code above is omitted\n\nmyjob = Job(\n    \"actor_with_args\",\n    args=dict(user_id=123, user_name=\"Alex\", user_messages=[\"This is your first message!\"]),\n)\n\nawait myjob.enqueue()\n\nawait asyncio.sleep(1.0)  # wait for the job to complete\n\nresult_bucket = await myjob.result\nprint(result_bucket)\n\n# code below is omitted\n</code></pre> <p>Info</p> <p>Results of recurring jobs will be overwritten.</p>"},{"location":"user_guide/arguments_and_results/#ids","title":"IDs","text":"<p>By default, an UUID4 will be generated upon creation of a job, both in case of an arguments bucket and a result bucket.</p> <p>You can pass your own IDs using appropriate arguments:</p> <pre><code>Job(\"some_job\", args_id=\"my_args_id\", result_id=\"my_result_id\")\n</code></pre>"},{"location":"user_guide/arguments_and_results/#ttl","title":"TTL","text":"<p>Repid also supports specifying Time-To-Live for both arguments and result buckets.</p> <pre><code>from datetime import timedelta\n\nJob(\"some_job\", args_ttl=timedelta(weeks=2), result_ttl=timedelta(days=5))\n</code></pre> <p>You can also set TTL to None, which equals to no expiration.</p> <pre><code>Job(\"some_job\", args_ttl=None, result_ttl=None)\n</code></pre> <p>By default, arguments buckets have no TTL, while result buckets have TTL of one day.</p> <p>Warning</p> <p>Not all bucket brokers may have native support for TTL, so be careful not to run out of memory.</p>"},{"location":"user_guide/deferred_scheduling/","title":"Deferred scheduling","text":"<p>You can create a job with delayed and recurring execution. Let's focus on the options in the next sections.</p>"},{"location":"user_guide/deferred_scheduling/#delayed-execution","title":"Delayed execution","text":"<p>To delay the execution of a Job, specify <code>deferred_until</code> argument.</p> <pre><code>from datetime import datetime\n\nfrom repid import Job\n\n# code above is omitted\n\nJob(\"delayed_job\", deferred_until=datetime(2077, 1, 1))  # (1)\n\n# code below is omitted\n</code></pre> <ol> <li>The job will be executed on the 1st of January in 2077.</li> </ol>"},{"location":"user_guide/deferred_scheduling/#recurring-execution","title":"Recurring execution","text":"<p>Warning</p> <p>Next execution time for a recurring job is set after the previous execution. Therefore, if a job wasn't processed or processing took longer than recurring time frame, next execution will be set to the next earliest time.</p>"},{"location":"user_guide/deferred_scheduling/#defer-by","title":"Defer by","text":"<p>If you want a job to be executed every equal period of time (e.g. every 10 minutes, every 2 days, etc.) you can specify <code>deferred_by</code> argument.</p> <pre><code>from datetime import timedelta\n\nfrom repid import Job\n\n# code above is omitted\n\nJob(\"every_2_days\", deferred_by=timedelta(days=2))\n\n# code below is omitted\n</code></pre>"},{"location":"user_guide/deferred_scheduling/#cron","title":"cron","text":"<p>If you want to specify a job with recurring execution in cron format, you will have to install repid with additional flag as follows:</p> <pre><code>pip install repid[cron]\n</code></pre> <p>It will install croniter package, which will be used internally to calculate next time of an execution.</p> <p>You can specify any cron string supported by croniter using <code>cron</code> argument of a Job.</p> <pre><code>from repid import Job\n\n# code above is omitted\n\nJob(\"every_day_at_noon\", cron=\"0 12 * * *\")\n\n# code below is omitted\n</code></pre>"},{"location":"user_guide/deferred_scheduling/#rescheduling-and-retries","title":"Rescheduling and retries","text":"<p>Rescheduling for a retry will take precedence over rescheduling for the next recurring iteration.</p> <p>Keep in mind, that depending on the way how your retries are set up, some recurring iterations might be skipped.</p> <p>If the number of retries was exceeded the job will be rescheduled for the next recurring iteration anyway.</p>"},{"location":"user_guide/deferred_scheduling/#combining","title":"Combining","text":"<p>Combining <code>deferred_by</code> and <code>cron</code> in one job is prohibited.</p> <p>Combining <code>deferred_until</code> with either <code>deferred_by</code> or <code>cron</code> will delay the first execution until <code>deferred_until</code> and recurrently continue using <code>deferred_by</code> or <code>cron</code>.</p>"},{"location":"user_guide/deferred_scheduling/#time-to-live","title":"Time-to-live","text":"<p>You can narrow the time of message consumption window using <code>ttl</code> argument. It will ensure that since latest scheduling hasn't passed any more time. If not, the message will be marked as 'not acknowledged' and put in a dead-letter queue.</p> <pre><code>from datetime import timedelta\n\nfrom repid import Job\n\n# code above is omitted\n\nJob(\"consume_me_faster_than_3_days\", ttl=timedelta(days=3))\n\n# code below is omitted\n</code></pre> <p>Note</p> <p>Every rescheduling of a Job resets time-to-live timer. Time of rescheduling will be considered the new starting point.</p>"},{"location":"user_guide/deferred_scheduling/#recap","title":"Recap","text":"<ol> <li>Delay job's execution using <code>deferred_until</code></li> <li>Create a recurring job using <code>deferred_by</code> or <code>cron</code></li> <li>Set <code>ttl</code> to ensure fast enough consumption</li> </ol>"},{"location":"user_guide/dependency_injection/","title":"Dependency injection","text":""},{"location":"user_guide/dependency_injection/#depends","title":"Depends","text":"<p>In your actor, you can declare a dependency as follows:</p> Python 3.10+Python 3.8+ <pre><code>from typing import Annotated\n\nfrom repid import Depends\n\n\ndef dependency_function() -&gt; str:\n    return \"Hello!\"\n\n\n@router.actor  # (1)\nasync def my_actor(\n    my_dependency: Annotated[str, Depends(dependency_function)]\n) -&gt; None:\n    print(my_dependency)  # (2)\n</code></pre> <ol> <li>Router declaration is omitted</li> <li>Will print <code>Hello!</code></li> </ol> <pre><code>from typing_extensions import Annotated  # (1)\nfrom repid import Depends\n\n\ndef dependency_function() -&gt; str:\n    return \"Hello!\"\n\n\n@router.actor  # (2)\nasync def my_actor(\n    my_dependency: Annotated[str, Depends(dependency_function)]\n) -&gt; None:\n    print(my_dependency)  # (3)\n</code></pre> <ol> <li>Annotated was added in Python 3.10, but you can use backported version from <code>typing_extenstions</code> in earlier versions</li> <li>Router declaration is omitted</li> <li>Will print <code>Hello!</code></li> </ol>"},{"location":"user_guide/dependency_injection/#sub-dependencies","title":"Sub-dependencies","text":"<p>Your dependency can also have some dependencies of its own!</p> Python 3.10+Python 3.8+ <pre><code>from typing import Annotated\n\nfrom repid import Depends\n\n\ndef subdependency_function() -&gt; str:\n    return \"world!\"\n\n\ndef dependency_function(\n    sub: Annotated[str, Depends(subdependency_function)]\n) -&gt; str:\n    return \"Hello \" + sub\n\n\n@router.actor  # (1)\nasync def my_actor(\n    my_dependency: Annotated[str, Depends(dependency_function)]\n) -&gt; None:\n    print(my_dependency)  # (2)\n</code></pre> <ol> <li>Router declaration is omitted</li> <li>Will print <code>Hello world!</code></li> </ol> <pre><code>from typing_extensions import Annotated  # (1)\nfrom repid import Depends\n\n\ndef subdependency_function() -&gt; str:\n    return \"world!\"\n\n\ndef dependency_function(\n    sub: Annotated[str, Depends(subdependency_function)]\n) -&gt; str:\n    return \"Hello \" + sub\n\n\n@router.actor  # (2)\nasync def my_actor(\n    my_dependency: Annotated[str, Depends(dependency_function)]\n) -&gt; None:\n    print(my_dependency)  # (3)\n</code></pre> <ol> <li>Annotated was added in Python 3.10, but you can use backported version from <code>typing_extenstions</code> in earlier versions</li> <li>Router declaration is omitted</li> <li>Will print <code>Hello world!</code></li> </ol>"},{"location":"user_guide/dependency_injection/#sync-and-async-dependencies","title":"Sync and Async dependencies","text":"<p>Your dependencies' functions can be both synchronous and asynchronous.</p>"},{"location":"user_guide/dependency_injection/#asynchronous","title":"Asynchronous","text":"<pre><code>async def dependency_function() -&gt; str:\n    await asyncio.sleep(0.1)  # (1)\n    return \"Hello world!\"\n\nDepends(dependency_function)\n</code></pre> <ol> <li>Imitates some async work</li> </ol>"},{"location":"user_guide/dependency_injection/#synchronous","title":"Synchronous","text":"<pre><code>def dependency_function() -&gt; str:\n    return \"Hello world!\"\n\nDepends(dependency_function)\n</code></pre>"},{"location":"user_guide/dependency_injection/#synchronous-cpu-heavy","title":"Synchronous (CPU-heavy)","text":"<p>In case your function is synchronous, it will be run in a thread pool executor to avoid blocking the event loop.</p> <p>You can also opt to run it in a process pool executor, if, for example, your function is CPU bound.</p> <pre><code>def dependency_function() -&gt; int:\n    # some CPU-heavy computation here\n    return 123\n\nDepends(dependency_function, run_in_process=True)\n</code></pre>"},{"location":"user_guide/dependency_injection/#overriding-dependencies","title":"Overriding dependencies","text":"<p>You can override a dependency (e.g. for test purposes).</p> <p>Beware global state mutation</p> <p>Overrides can be extremly helpful in tests, especially when you want to do complete end-to-end testing.</p> <p>However, as overrides are essentially a global state mutations, you have to be very careful if they are used inside of the application itself.</p> <pre><code>def dependency_function() -&gt; str:\n    return \"Hello!\"\n\nd = Depends(dependency_function)\n\nd.override(lambda: \"Overriden!\")  # (1)\n\n@router.actor\nasync def my_actor(\n    my_dependency: Annotated[str, d]\n) -&gt; None:\n    print(my_dependency)  # (2)\n</code></pre> <ol> <li>You can specify any other function here and even select <code>run_in_process</code> if you need</li> <li>Will print <code>Overriden!</code></li> </ol>"},{"location":"user_guide/initial_setup/","title":"Initial setup","text":""},{"location":"user_guide/initial_setup/#app-structure","title":"App structure","text":"<p>Usually repid apps are split up in two parts: producer (the one, who enqueues/creates new jobs) and consumer (the one who actually does all the heavy lifting).</p> <p>The framework is intentionally designed to separate those two parts and you may even have them in different codebases.</p> <p>With that said, for simplicity, most of the examples in docs are using <code>InMemoryMessageBroker</code>, which requires both sides to be run in one process.</p>"},{"location":"user_guide/initial_setup/#brokers","title":"Brokers","text":"<p>First of all you will have to establish a connection using one of broker implementations.</p> <p>Repid provides some brokers (RabbitMQ, Redis, etc.) out-of-the-box, but you will have to specify extra dependencies for them to work:</p> <p>For RabbitMQ install</p> <pre><code>pip install repid[amqp]\n</code></pre> <p>For Redis install</p> <pre><code>pip install repid[redis]\n</code></pre> <p>Mostly for test purposes, repid also provides <code>InMemoryMessageBroker</code> &amp; <code>InMemoryBucketBroker</code>, which are using RAM to store data, thus requiring your app to run in one context/process/etc. You don't need any extra dependencies to use those.</p> <p>Different brokers may have different initialization parameters, but often the pattern is to simply pass a connection string. Bucket brokers may also have some way of specifying whether they are supposed to be used to store results or not. This will come in handy later.</p> <p>Let's suppose we want to use <code>RabbitMessageBroker</code>, so after we've installed the necessary dependencies, you may write something like this:</p> <pre><code>import os\nfrom repid import RabbitMessageBroker\n\nmy_broker = RabbitMessageBroker(dsn=os.environ.get(\"RABBIT_CONNECTION_STRING\"))\n</code></pre>"},{"location":"user_guide/initial_setup/#connection","title":"Connection","text":"<p>After creating a broker instance you will have to create a <code>Connection</code>. Connection is a data structure which will tie your message broker, bucker broker, result bucket broker &amp; middleware.</p> <p>Upon creation of a <code>Connection</code>, it will create a new <code>Middleware</code> instance and assign it to supplied brokers. Thus, calling a broker before it was assigned a middleware won't call any middleware functions.</p> <p>Each <code>Connection</code> instance has <code>is_open</code> boolean flag. This flag is only updated when connection instance itself is changing state (== using <code>connect</code> &amp; <code>disconnect</code> methods).</p> <p>Warning</p> <p><code>is_open</code> flag doesn't track state of underlying broker connections. <code>Connection</code> class is not responsible for reconnection in case of a failure.</p> <p>Using our previous example with <code>RabbitMessageBroker</code>, let's create a <code>Connection</code>:</p> <pre><code>import os\nfrom repid import Connection, RabbitMessageBroker\n\nmy_broker = RabbitMessageBroker(dsn=os.environ.get(\"RABBIT_CONNECTION_STRING\"))\n\nmy_connection = Connection(my_broker)\n</code></pre> <p>Or here is another example with bucket brokers also specified:</p> <pre><code>import os\nfrom repid import Connection, RabbitMessageBroker, RedisBucketBroker\n\nmy_connection = Connection(\n    message_broker=RabbitMessageBroker(dsn=os.environ.get(\"RABBIT_CONNECTION_STRING\")),\n    args_bucket_broker=RedisBucketBroker(dsn=os.environ.get(\"REDIS_ARGS_CONNECTION_STRING\")),\n    results_bucket_broker=RedisBucketBroker(\n        dsn=os.environ.get(\"REDIS_RESULT_CONNECTION_STRING\"),\n        use_result_bucket=True,\n    ),\n)\n</code></pre>"},{"location":"user_guide/initial_setup/#magic","title":"Magic","text":"<p>...or not really </p> <p>So now you have this connection instance, but you would need to provide it to every object manually. To avoid doing so, create a <code>Repid</code> instance and provide connection to it. Then you will be able to use <code>magic</code> async context manager, which will automatically bind your connection to the needed objects.</p> <pre><code>from repid import Repid, Job\n\n# `my_connection` definition is omitted\n\napp = Repid(my_connection)\n\nasync def main() -&gt; None:\n    async with app.magic():\n        j = Job(\"my_awesome_job\")  # (1)\n        await j.enqueue()\n\n# `main` function call is omitted\n</code></pre> <ol> <li>You don't have to supply <code>_connection</code> argument to the <code>Job</code>, it's done auto-magically</li> </ol> <p>If you want more control over the magic, you can use <code>magic_connect</code> &amp; <code>magic_disconnect</code>. So here is how you can use it with <code>FastAPI</code>:</p> <pre><code>from fastapi import FastAPI\nfrom repid import Repid, Job\n\n# `my_connection` definition is omitted\n\nrepid_app = Repid(my_connection)\n\nfastapi_app = FastAPI()\n\n\n@fastapi_app.on_event(\"startup\")\nasync def open_repid_connection() -&gt; None:\n    await repid_app.magic_connect()\n\n\n@fastapi_app.on_event(\"shutdown\")\nasync def close_repid_connection() -&gt; None:\n    await repid_app.magic_disconnect()\n\n\n@fastapi_app.post(\"/create-job\")\nasync def create_job() -&gt; None:\n    await Job(\"my_awesome_fastapi_job\").enqueue()  # (1)\n</code></pre> <ol> <li>Again, you don't have to supply <code>_connection</code> argument to the <code>Job</code>, as long as <code>magic_connect</code> was called before.</li> </ol>"},{"location":"user_guide/initial_setup/#but-how-does-it-work","title":"...but how does it work?","text":"<p>Internally, <code>Repid</code> class (not to be confused with instances of the <code>Repid</code> class) holds a thread-local variable, which is used to store <code>Connection</code> object. It also calls <code>connect</code>/<code>disconnect</code> method so you don't have to!</p> <p>Warning</p> <p>Keep in mind that as connections are meant to be long-lived</p> <pre><code>async with app.magic()\n    ...\n</code></pre> <p>doesn't close connection on exit by default!</p> <p>To close the connection, set <code>auto_disconnect</code> flag to True</p> <pre><code>async with app.magic(auto_disconnect=True)\n    ...\n</code></pre>"},{"location":"user_guide/initial_setup/#recap","title":"Recap","text":"<ol> <li>Create a broker</li> <li>Submit it to a <code>Connection</code></li> <li>Add it to <code>Repid</code> to get the magic</li> <li>Use it!</li> </ol> <pre><code>import asyncio\nimport os\n\nfrom repid import Connection, Job, RabbitMessageBroker, RedisBucketBroker, Repid\n\napp = Repid(\n    Connection(\n        message_broker=RabbitMessageBroker(dsn=os.environ.get(\"RABBIT_CONNECTION_STRING\")),\n        args_bucket_broker=RedisBucketBroker(dsn=os.environ.get(\"REDIS_ARGS_CONNECTION_STRING\")),\n        results_bucket_broker=RedisBucketBroker(\n            dsn=os.environ.get(\"REDIS_RESULT_CONNECTION_STRING\"),\n            use_result_bucket=True,\n        ),\n    )\n)\n\n\nasync def main() -&gt; None:\n    async with app.magic():\n        await Job(\"my_awesome_job\").enqueue()\n\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre>"},{"location":"user_guide/jobs_actors_and_workers/","title":"Jobs, Actors and Workers","text":"<p>Now, that you now how to properly set up a connection, let's focus on creation of jobs and their processing.</p>"},{"location":"user_guide/jobs_actors_and_workers/#jobs","title":"Jobs","text":"<p>Job is a data structure, which describes what and how you want to be executed.</p> <p>As you may want the execution to be periodic or to be retried in case of a failure, 1 job doesn't necessarily translate to 1 message on the broker's side.</p> <p>The only required parameter of a Job is <code>name</code>. It specifies what <code>actor</code> has to be called on the consumer side. Routing is done on application level.</p>"},{"location":"user_guide/jobs_actors_and_workers/#simple-job","title":"Simple job","text":"<p>It's extremely easy to create a job:</p> <pre><code>import asyncio\n\nfrom repid import Connection, InMemoryMessageBroker, Job, Repid\n\napp = Repid(Connection(InMemoryMessageBroker()))\n\n\nasync def main() -&gt; None:\n    async with app.magic():\n        Job(name=\"my_awesome_job\")\n\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre>"},{"location":"user_guide/jobs_actors_and_workers/#jobs-and-queues","title":"Jobs and queues","text":"<p>To schedule an execution of a job, you have to call <code>enqueue</code> method...</p> <pre><code># code above is omitted\n\nasync with app.magic():\n    j = Job(name=\"my_awesome_job\")\n\n    await j.enqueue()  # \ud83d\udca5 KeyError: 'default'\n\n# code below is omitted\n</code></pre> <p>...but it will fail, because we haven't initialized the default queue. Let's fix it:</p> <pre><code># code above is omitted\n\nasync with app.magic():\n    j = Job(name=\"my_awesome_job\")  # (1)\n    await j.queue.declare()\n    await j.enqueue()\n\n    # \u2705 Success!\n\n# code below is omitted\n</code></pre> <ol> <li>By default queue is set to <code>Queue(name=\"default\")</code></li> </ol> <p>You may also want to initialize queue(-s) preemptively, in, e.g., <code>setup</code> function.</p> <pre><code>from repid import Queue\n\n# code above is omitted\n\nasync def setup() -&gt; None:\n    async with app.magic():\n        await Queue().declare()  # (1)\n        await Queue(name=\"my_awesome_queue\").declare()\n\n\n# code below is omitted\n</code></pre> <ol> <li>Will declare a queue with name set to <code>default</code></li> </ol> <p>Tip</p> <p>Usually brokers support multiple queue declarations (== re-declaring already existing queue will have no effect), meaning that you can declare a queue on every app startup to ensure correct workflow of your application.</p> <p>You can specify <code>queue</code> argument either as a string or as a <code>Queue</code> object. In case of a string it will be automatically converted to a <code>Queue</code> object during <code>Job</code> object initialization.</p> <pre><code>my_awesome_job = Job(name=\"my_awesome_job\", queue=\"non-default-queue\")\nanother_job = Job(name=\"another_job\", queue=Queue(\"another-queue\"))\n\nprint(type(my_awesome_job.queue))  # repid.Queue\nprint(type(another_job.queue))  # repid.Queue\n</code></pre>"},{"location":"user_guide/jobs_actors_and_workers/#job-priority","title":"Job priority","text":"<p>You can specify priority of the job using <code>PrioritiesT</code> enum. Default is set to <code>PrioritiesT.MEDIUM</code>. <code>HIGH</code>, <code>MEDIUM</code> &amp; <code>LOW</code> levels are officially supported.</p> <pre><code>from repid import Job, PrioritiesT\n\n# code above is omitted\n\nJob(\"awesome_job_with_priority\", priority=PrioritiesT.HIGH)\n\n# code below is omitted\n</code></pre>"},{"location":"user_guide/jobs_actors_and_workers/#job-id-and-uniqueness","title":"Job id and uniqueness","text":"<p>By default Job doesn't have any id and on every <code>enqueue</code> call a message will be generated a new id using <code>uuid.uuid4().hex</code>. Therefore, by default, a Job isn't considered unique.</p> <p>You can check it with <code>is_unique</code> flag.</p> <pre><code>print(Job(\"non_unique_job\").is_unique)  # False\n</code></pre> <p>If you specify <code>id_</code> argument - it will not be regenerated on every call of <code>enqueue</code> and therefore the Job is considered unique.</p> <pre><code>print(Job(\"unique_job\", id_=\"my_unique_id\").is_unique)  # True\n</code></pre> <p>Warning</p> <p>Some, although not all, brokers are ensuring that there are no messages with the same id in the queue.</p>"},{"location":"user_guide/jobs_actors_and_workers/#retries","title":"Retries","text":"<p>If you want a Job to be retried in case of a failure during the execution - specify <code>retries</code> argument. Default is set to <code>0</code>, which means that the Job will only be executed once and put in a dead-letter queue in case of a failure.</p> <pre><code>Job(\"retryable_job\", retries=3)\n</code></pre>"},{"location":"user_guide/jobs_actors_and_workers/#timeout","title":"Timeout","text":"<p>You can also specify maximum allowed execution time for a Job using <code>timeout</code> argument. Default is set to <code>10 minutes</code>.</p> <pre><code>from datetime import timedelta\n\n# code above is omitted\n\nJob(\"very_fast_job\", timeout=timedelta(seconds=5))\nJob(\"very_slow_job\", timeout=timedelta(hours=2))\n\n# code below is omitted\n</code></pre> <p>Execution timeout is also a valid reason for a retry.</p> <p>Tip</p> <p>You should sensibly limit Job's timeout, as it can be a deciding factor for rescheduling in case of a worker disconnection.</p>"},{"location":"user_guide/jobs_actors_and_workers/#actors","title":"Actors","text":"<p>Actors are functions, which are meant to be executed when a worker (== consumer) receives a message.</p> <p>To create an actor you first have to create a <code>Router</code> and then use <code>Router.actor</code> as a decorator for your function.</p> <pre><code>from repid import Router\n\nmy_router = Router()\n\n\n@my_router.actor\nasync def my_awesome_function() -&gt; None:\n    print(\"Hello Repid!\")\n</code></pre> <p>Note</p> <p>Actor decorator does not anyhow change the decorated function. The initial function remains callable as it was before.</p>"},{"location":"user_guide/jobs_actors_and_workers/#actor-name","title":"Actor name","text":"<p>By default, name of an actor is the same as the name of the function. You can override it with <code>name</code> argument.</p> <pre><code>from repid import Router\n\nmy_router = Router()\n\n\n@my_router.actor(name=\"another_name\")\nasync def my_awesome_function() -&gt; None:\n    print(\"Hello Repid!\")\n</code></pre>"},{"location":"user_guide/jobs_actors_and_workers/#actor-queue","title":"Actor queue","text":"<p>You can also specify what queue should actor listen on using <code>queue</code> argument.</p> <pre><code>@my_router.actor(queue=\"another_queue\")\nasync def my_awesome_function() -&gt; None:\n    ...\n</code></pre>"},{"location":"user_guide/jobs_actors_and_workers/#thread-vs-process","title":"Thread vs Process","text":"<p>If your function is synchronous, you can specify if you want it to be run in a separate process instead of a thread by setting <code>run_in_process</code> to True.</p> <pre><code>@my_router.actor(run_in_process=True)\ndef my_synchronous_function() -&gt; None:\n    ...\n</code></pre> Warning <p>If you are running on the <code>emscripten</code> platform (e.g. PyScript) <code>run_in_process</code> setting doesn't take any effect.</p>"},{"location":"user_guide/jobs_actors_and_workers/#retry-policy","title":"Retry Policy","text":"<p>In case of a retry, application will reschedule the message with a delay. The delay is calculated using a retry policy, which defaults to exponential. You can override the behavior with <code>retry_policy</code> argument.</p> <pre><code>from repid import Router, default_retry_policy_factory\n\nmy_router = Router()\n\n\n@my_router.actor(\n    retry_policy=default_retry_policy_factory(\n        min_backoff=60,\n        max_backoff=86400,\n        multiplier=5,\n        max_exponent=15,\n    )\n)\nasync def my_exceptional_function() -&gt; None:\n    raise Exception(\"Some random exception.\")\n</code></pre> <p>...or you can use practically any function, which confirms to <code>RetryPolicyT</code>.</p> <pre><code>from repid import Router\n\nmy_router = Router()\n\n\n@my_router.actor(retry_policy=lambda retry_number=1: retry_number * 100)\nasync def my_exceptional_function() -&gt; None:\n    raise Exception(\"Some random exception.\")\n</code></pre>"},{"location":"user_guide/jobs_actors_and_workers/#workers","title":"Workers","text":"<p>Workers are controllers, which are responsible for receiving messages and executing related actors.</p>"},{"location":"user_guide/jobs_actors_and_workers/#workers-and-routers","title":"Workers and Routers","text":"<p>Workers are also routers. You can assign actors directly to them.</p> <pre><code>import asyncio\n\nfrom repid import Connection, InMemoryMessageBroker, Job, Repid, Worker\n\napp = Repid(Connection(InMemoryMessageBroker()))\n\n\nasync def main() -&gt; None:\n    async with app.magic():\n        my_worker = Worker()\n\n        @my_worker.actor\n        async def my_func() -&gt; None:\n            print(\"Hello!\")\n\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre> <p>You can include actors from other routers into a worker.</p> <p>Warning</p> <p>Adding actor with already existing name will override previously stored actor.</p> <pre><code>router = Router()\nother_router = Router()\n\n# code above is omitted\n\nWorker(routers=[router, other_router])\n\n# or\n\nmy_worker = Worker()\n\nmy_worker.include_router(router)\nmy_worker.include_router(other_router)\n\n# code below is omitted\n</code></pre>"},{"location":"user_guide/jobs_actors_and_workers/#running-a-worker","title":"Running a Worker","text":"<p>To run a worker simply call <code>run</code> method. The worker will be running until it receives a signal (<code>SIGINT</code> or <code>SIGTERM</code>, by default) or until it reaches <code>messages_limit</code>, which by default is set to infinity.</p> <p>Tip</p> <p>Worker will declare all queues that it's aware about (via assigned actors) on the execution of <code>run</code> method. To override this behavior set <code>auto_declare</code> flag to False.</p> <pre><code>import asyncio\n\nfrom repid import Connection, InMemoryMessageBroker, Repid, Worker\n\napp = Repid(Connection(InMemoryMessageBroker()))\n\n\nasync def main() -&gt; None:\n    async with app.magic(auto_disconnect=True):\n        my_worker = Worker()\n        await my_worker.run()\n\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre> <p>After worker receives a signal it will attempt a graceful shutdown. It means that it will stop receiving new messages and wait for <code>graceful_shutdown_time</code> (default: 25 seconds) to let already running actors complete.</p> <p>Note</p> <p>Default <code>graceful_shutdown_time</code> is set to 25 seconds because default Kubernetes timeout after sending <code>SIGTERM</code> and before sending <code>SIGKILL</code> is set to 30 seconds. 5 second buffer is provided to ensure that every uncompleted task will be rejected before ungraceful termination.</p> <p>Any actor which exceeds that period will be forced to stop and corresponding message will be rejected, meaning that the message broker will be responsible for requeueing the message and retry counter will not be increased.</p> <pre><code>from signal import SIGQUIT\n\n# code above is omitted\n\nWorker(\n    graceful_shutdown_time=100.0,  # seconds\n    messages_limit=10_000,\n    handle_signals=[SIGQUIT],\n)\n\n# code below is omitted\n</code></pre> Warning <p>If you are running on the <code>emscripten</code> platform (e.g. PyScript) you will have to manually disable signal handling by setting <code>handle_signals</code> to an empty list <code>= []</code>, as the platform doesn't support signal handling.</p> <p>After Worker is done running, it will return an internal <code>_Runner</code> object, which you can use to retrieve information about amount of actor runs.</p> <pre><code>import asyncio\n\nfrom repid import Connection, InMemoryMessageBroker, Repid, Worker\n\napp = Repid(Connection(InMemoryMessageBroker()))\n\n\nasync def main() -&gt; None:\n    async with app.magic(auto_disconnect=True):\n        my_worker = Worker()\n        runner = await my_worker.run()\n        print(f\"Total actor runs: {runner.processed}\")\n\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre>"},{"location":"user_guide/jobs_actors_and_workers/#recap","title":"Recap","text":"<ol> <li>Declare a <code>Queue</code> and enqueue a <code>Job</code></li> <li>Create an <code>Actor</code></li> <li>Assign it to a <code>Worker</code> directly or via a <code>Router</code></li> <li>Run the <code>Worker</code></li> </ol> <pre><code>import asyncio\n\nimport repid\n\napp = repid.Repid(repid.Connection(repid.InMemoryMessageBroker()))\n\nrouter = repid.Router()\n\n\n@router.actor\nasync def awesome_hello() -&gt; None:\n    print(\"Hello from an actor!\")\n\n\nasync def producer_side() -&gt; None:\n    async with app.magic():\n        await repid.Queue().declare()\n        await repid.Job(\"awesome_hello\").enqueue()\n\n\nasync def consumer_side() -&gt; None:\n    async with app.magic(auto_disconnect=True):\n        await repid.Worker(routers=[router], messages_limit=1).run()\n\n\nasync def main() -&gt; None:\n    await producer_side()\n    await consumer_side()\n\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre>"},{"location":"user_guide/message_and_eager_response/","title":"Message &amp; Eager response","text":""},{"location":"user_guide/message_and_eager_response/#message-inside-of-an-actor","title":"Message inside of an Actor","text":"<p>There might be a situation where you would like to know the exact details of your incoming message.</p> <p>You can get access to those details by specifying an argument, typed with <code>MessageDependency</code>.</p> <pre><code>from repid import MessageDependency\n\n\n@router.actor\nasync def my_actor(msg: MessageDependency) -&gt; None:  # (1)\n    ...\n</code></pre> <ol> <li>Message will be automatically injected into your actor</li> </ol>"},{"location":"user_guide/message_and_eager_response/#eager-response","title":"Eager response","text":"<p>When you received a message inside of your actor, you have ability to trigger eager response, e.g.</p> <pre><code>@router.actor\nasync def my_actor(msg: MessageDependency) -&gt; None:\n    await msg.ack()\n    print(\"Hello?\")  # (1)\n</code></pre> <ol> <li>Will not execute, as you have ack-ed the message, thus exiting actor's context.</li> </ol> <p>However, <code>ack</code> is not the only available eager response, so here is the full list:</p> <ol> <li><code>ack</code> - Acknowledge</li> <li><code>nack</code> - Not acknowledge (i.e. put message in dead-letter queue)</li> <li><code>reject</code> - Reject receival (i.e. return the message to the initial queue)</li> <li><code>retry</code> - Retry execution (increments retry count, can raise <code>ValueError</code> if amount of retries was exceeded)</li> <li><code>force_retry</code> - Retry execution even if amount of retries was exceeded</li> <li><code>reschedule</code> - Re-schedule the message. Can be useful if payload or parameters of the message are changed.</li> </ol>"},{"location":"user_guide/message_and_eager_response/#setting-result-for-eager-response","title":"Setting result for eager response","text":"<p>If you would like to return a result of actor's execution, you can do one of the following:</p>"},{"location":"user_guide/message_and_eager_response/#set-a-result","title":"Set a result","text":"<pre><code>@router.actor\nasync def my_actor(msg: MessageDependency) -&gt; int:\n    msg.set_result(123)\n    await msg.ack()\n</code></pre>"},{"location":"user_guide/message_and_eager_response/#set-an-exception","title":"Set an exception","text":"<pre><code>@router.actor\nasync def my_actor(msg: MessageDependency) -&gt; int:\n    msg.set_exception(Exception(\"Terrible error happened during execution!\"))\n    await msg.ack()\n</code></pre> <p><code>set_result</code> or <code>set_exception</code> will be executed after an eager response. Only one can be used at a time, and if set multiple times - only the latest will be executed.</p>"},{"location":"user_guide/message_and_eager_response/#adding-callback-to-be-executed-after-eager-response","title":"Adding callback to be executed after eager response","text":"<p>As eager response exits actor's scope, you won't be able to execute anything after it. To counteract this, you can set any callable (both sync and async) as a callback using <code>add_callback</code> method:</p> <pre><code>def my_callback() -&gt; None:\n    # do smth\n\n\nasync def my_async_callback() -&gt; None:\n    # do smth\n\n\n@router.actor\nasync def my_actor(msg: MessageDependency) -&gt; int:\n    msg.add_callback(my_callback)\n    msg.set_result(123)\n    msg.add_callback(my_async_callback)\n    await msg.ack()\n</code></pre> <p>Multiple callbacks can be set, and if so - they will be executed in the order of submission (including <code>set_result</code> and <code>set_exception</code>).</p> <p>Callbacks can't have any non-default arguments.</p>"},{"location":"user_guide/testing/","title":"Testing","text":"<p>Let's focus on testing our code with Repid.</p>"},{"location":"user_guide/testing/#preparation","title":"Preparation","text":"<p>Repid provides pytest plugin out-of-the box, but to use it you will have to make sure you have pytest and pytest-asyncio plugin installed.</p> <p>Optionally, you can specify repid to install with test dependencies:</p> <pre><code>pip install repid[test]\n</code></pre> <p>In the following examples will assume you have created an application with the following structure:</p> <pre><code>.\n\u251c\u2500\u2500 myapp\n\u2502   \u2514\u2500\u2500 app.py\n\u2514\u2500\u2500 tests\n    \u2514\u2500\u2500 test_app.py\n</code></pre> <p>We will use a simple actor from one of the previous examples:</p> app.py<pre><code>from repid import Router\n\nmyrouter = Router()\n\n\n@router.actor\nasync def actor_with_args(user_id: int, user_name: str, user_messages: list[str]) -&gt; list[str]:\n    user_message = f\"Hi {user_name}! Your id is: {user_id}.\"\n    user_messages.append(user_message)\n    return user_messages\n</code></pre>"},{"location":"user_guide/testing/#writing-tests","title":"Writing tests","text":"<p>We can use the fact that Repid doesn't anyhow modify actor function to our advantage and write a very simple unit test.</p> test_app.py<pre><code>from myapp.app import actor_with_args\n\n\nasync def test_actor_with_args() -&gt; None:\n    expected = [\"Hi Alex! Your id is: 123.\"]\n    actual = actor_with_args(user_id=123, user_name=\"Alex\", user_messages=[])\n    assert actual == expected\n</code></pre> <p>However, we are not able to enqueue a <code>Job</code> to call our actor. That's where Repid's pytest plugin comes to the rescue.</p> test_app.py<pre><code>import pytest\nimport repid\nfrom myapp.app import actor_with_args, myrouter\n\n\n@pytest.mark.repid  # (1)\nasync def test_actor_by_enqueueing_a_job() -&gt; None:\n    await repid.Queue().declare()\n\n    j = repid.Job(\"actor_with_args\", args=dict(user_id=123, user_name=\"Alex\", user_messages=[]))\n    await j.enqueue()  # (2)\n\n    assert (await j.result) is None  # (3)\n\n    await repid.Worker(routers=[myrouter], messages_limit=1).run()  # (4)\n\n    assert (await j.result).data == [\"Hi Alex! Your id is: 123.\"]  # (5)\n</code></pre> <ol> <li>Mark test function with Repid marker to activate some of the plugin features.</li> <li>Enqueue a Job. The plugin takes care of creating an in-memory broker     and passing the connection automatically.</li> <li>The Job is enqueued but not yet processed, therefore the result is None.</li> <li>For now, we manually create a Worker to process our Job.     We will cover how to do it automatically in the next steps.</li> <li>After the Job was processed, we should be able to retrieve the result.</li> </ol> <p>If we pass our Router to the plugin's marker, the plugin will take care of the Job's processing.</p> test_app.py<pre><code>import pytest\nimport repid\nfrom myapp.app import actor_with_args, myrouter\n\n\n@pytest.mark.repid.with_args(routers=[myrouter])  # (1)\nasync def test_actor_by_enqueueing_a_job() -&gt; None:\n    await repid.Queue().declare()\n\n    j = repid.Job(\"actor_with_args\", args=dict(user_id=123, user_name=\"Alex\", user_messages=[]))\n    await j.enqueue()  # (2)\n\n    assert (await j.result).data == [\"Hi Alex! Your id is: 123.\"]\n</code></pre> <ol> <li>Using <code>.with_args(routers=[])</code> you are able to pass a list of routers to the plugin.     Any Actor, included in those routers, will be automatically processed.</li> <li>Processing of the enqueued message will happen just after it was enqueued,     but before <code>.enqueue()</code> will return to the test function.</li> </ol> <p>The plugin can also declare all the queues, which your passed routers are aware about.</p> test_app.py<pre><code>import pytest\nimport repid\nfrom myapp.app import actor_with_args, myrouter\n\n\n@pytest.mark.repid.with_args(routers=[myrouter], declare_all_known_queues=True)\nasync def test_actor_by_enqueueing_a_job() -&gt; None:\n    j = repid.Job(\"actor_with_args\", args=dict(user_id=123, user_name=\"Alex\", user_messages=[]))\n    await j.enqueue()  # (1)\n\n    assert (await j.result).data == [\"Hi Alex! Your id is: 123.\"]\n</code></pre> <ol> <li>No need to declare a queue, plugin will take care of it.</li> </ol>"},{"location":"user_guide/testing/#using-fixtures","title":"Using fixtures","text":"What is a pytest fixture? <p>Pytest fixture is like a function, result of which can be injected in your tests.</p> <p>If you want to learn more about pytest fixtures, you can check out documentation here.</p> <p>Repid provides a couple of pytest fixtures for you to use in your tests.</p>"},{"location":"user_guide/testing/#mocked-actor-fixture","title":"Mocked actor fixture","text":"<p>When you pass a Router to Repid's testing plugin, it wraps all Actor calls in <code>MagicMock</code>. To access the mock, use <code>repid_get_mocked_actor</code> fixture. You can then use the mock to assert calls, specify side effects, etc.</p> test_app.py<pre><code>import pytest\nimport repid\nfrom unittest.mock import MagicMock\nfrom myapp.app import actor_with_args, myrouter\n\n\n@pytest.mark.repid.with_args(routers=[r], declare_all_known_queues=True)\nasync def test_actor_with_mock(repid_get_mocked_actor: repid.GetMockedActorT) -&gt; None:\n    j = repid.Job(\"actor_with_args\", args=dict(user_id=123, user_name=\"Alex\", user_messages=[]))\n\n    my_mock: MagicMock = repid_get_mocked_actor(\"actor_with_args\")\n\n    my_mock.assert_not_called()\n\n    await j.enqueue()\n\n    my_mock.assert_called_once_with(user_id=123, user_name=\"Alex\", user_messages=[])\n</code></pre>"},{"location":"user_guide/testing/#event-log-fixture","title":"Event log fixture","text":"<p>When testing some specific behavior of the library, you may want to ensure that all of the necessary broker methods were called correctly. To do so, utilize <code>repid_get_event_log</code> fixture.</p> test_app.py<pre><code>import pytest\nimport repid\nfrom myapp.app import actor_with_args, myrouter\n\n\n@pytest.mark.repid.with_args(routers=[myrouter])\nasync def test_actor_with_event_log(repid_get_event_log: repid.GetEventLogT) -&gt; None:\n    j = repid.Job(\"actor_with_args\", args=dict(user_id=123, user_name=\"Alex\", user_messages=[]))\n    await j.queue.declare()\n    await j.enqueue()\n\n    eventlog: list[repid.EventLog] = repid_get_event_log()  # (1)\n    assert len(eventlog) == 7\n    assert eventlog[0].function == \"queue_declare\"  # (2)\n    assert eventlog[1].function == \"store_bucket\"\n    assert eventlog[2].function == \"enqueue\"\n    assert eventlog[3].function == \"consume\"\n    assert eventlog[4].function == \"get_bucket\"\n    assert eventlog[5].function == \"ack\"\n    assert eventlog[6].function == \"store_bucket\"\n</code></pre> <ol> <li>Event log always comes sorted by the time of the execution.</li> <li>See <code>repid.EventLog</code> for other possible arguments.</li> </ol>"},{"location":"user_guide/testing/#in-memory-queue-fixture","title":"In-memory queue fixture","text":"<p>By default you are using in-memory broker during your tests. If you want to get low-level access to the underlying queue implementation you can use <code>repid_get_in_memory_queue</code> fixture.</p> test_app.py<pre><code>import pytest\nimport repid\nfrom myapp.app import actor_with_args\n\n\n@pytest.mark.repid  # (1)\nasync def test_get_queue(repid_get_in_memory_queue: repid.GetInMemoryQueueT) -&gt; None:\n    j = repid.Job(\"actor_with_args\", args=dict(user_id=123, user_name=\"Alex\", user_messages=[]))\n\n    in_memory_queue = repid_get_in_memory_queue(j.queue)  # (2)\n    assert in_memory_queue is None\n\n    for _ in range(10):\n        await j.enqueue()\n\n    in_memory_queue = repid_get_in_memory_queue(j.queue)\n    assert in_memory_queue.simple.qsize() == 10\n</code></pre> <ol> <li>We are intentionally not specifying our Router here, as otherwise all enqueued messages would've     been processed and therefore retrieved from the queue.</li> <li>You can also use string queue representation - <code>repid_get_in_memory_queue(\"default\")</code>.</li> </ol>"},{"location":"user_guide/testing/#bigger-test-suites","title":"Bigger test suites","text":"<p>You can mark whole module by specifying Repid's marker in pytestmark.</p> <pre><code>import pytest\nfrom myapp.app import myrouter\n\npytestmark = pytest.mark.repid.with_args(routers=[myrouter])\n</code></pre> <p>If for any reason you would like to disable automatic in-memory connection in a test - set <code>autoconnection</code> to False:</p> <pre><code>import pytest\nfrom myapp.app import myrouter\n\npytestmark = pytest.mark.repid.with_args(routers=[myrouter])\n\n\n@pytest.mark.repid.with_args(autoconnection=False)  # (1)\nasync def test_without_repid_connection() -&gt; None:\n    ...\n</code></pre> <ol> <li>The nearest marker to the test function is taken into account,     when considering to disable autoconnection.</li> </ol>"}]}