{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#repid","title":"Repid","text":"<p> Repid framework: simple to use, fast to run and extensible to adopt job scheduler. </p> <p> </p>"},{"location":"#example","title":"Example","text":"<p>Here is how the easiest example of producer-consumer application can look like.</p> <p>Producer:</p> <pre><code>import asyncio\nfrom repid import Connection, Job, RabbitMessageBroker, Repid\napp = Repid(Connection(RabbitMessageBroker(\"amqp://user:password@localhost:5672\")))\nasync def main() -&gt; None:\nasync with app.magic():\nawait Job(name=\"awesome_job\").enqueue()\nasyncio.run(main())\n</code></pre> <p>Consumer:</p> <pre><code>import asyncio\nfrom repid import Connection, RabbitMessageBroker, Repid, Router, Worker\napp = Repid(Connection(RabbitMessageBroker(\"amqp://user:password@localhost:5672\")))\nrouter = Router()\n@router.actor\nasync def awesome_job() -&gt; None:\nprint(\"Hello async jobs!\")\nawait asyncio.sleep(1.0)\nasync def main() -&gt; None:\nasync with app.magic():\nawait Worker(routers=[router]).run()\nasyncio.run(main())\n</code></pre>"},{"location":"#install","title":"Install","text":"<p>Repid supports Python versions 3.8 and up and is installable via <code>pip</code>.</p> <pre><code>pip install repid\n</code></pre> <p>There are also a couple of additional dependencies you may want to install, depending on your use case, e.g.</p> <pre><code>pip install repid[amqp, redis, cron]\n</code></pre>"},{"location":"#why-repid","title":"Why repid?","text":""},{"location":"#asyncio","title":"Asyncio","text":"<p><code>Repid</code> is built around <code>asyncio</code>. It means it's pretty fast. And you don't have to worry that it will slow down your other asyncio-driven code.</p>"},{"location":"#ease-of-integration","title":"Ease of integration","text":"<p>There is an abstraction layer on top of other queue solutions. It means that even if <code>repid</code> doesn't provide some broker out of the box, you will be able to write your own.</p>"},{"location":"#built-with-microservices-in-mind","title":"Built with microservices in mind","text":"<p>Your producer and consumer can be running in different containers, <code>repid</code> will handle it just fine.</p>"},{"location":"#can-be-used-with-other-languages","title":"Can be used with other languages","text":"<p><code>Repid</code> uses json (de-)serialization by default, which makes integration with other languages as easy as possible. You're also able to easily override default (de-)serialization behavior thanks to PEP 544 Protocols.</p>"},{"location":"#integrated-scheduling","title":"Integrated scheduling","text":"<p><code>Repid</code> has its own scheduling mechanisms. You can delay job execution until some date or even execute it every once in a while. No need for extra dependencies!</p>"},{"location":"#inspiration","title":"Inspiration","text":"<p><code>Repid</code> is inspired by <code>dramatiq</code> and <code>arq</code>.</p>"},{"location":"#license","title":"License","text":"<p>Repid is distributed under the terms of the MIT license. Please see License.md for more information.</p> <p>Repid's logo is distributed under the terms of the CC BY-NC 4.0 license. It is originally created by ari_the_crow_.</p>"},{"location":"contributing/","title":"Contributing to repid","text":"<p>Your contributions are invaluable to our community - thank you for being a part of the journey!</p>"},{"location":"contributing/#development-setup","title":"Development setup","text":""},{"location":"contributing/#quick-overview","title":"Quick overview","text":"<ol> <li>Create a fork of repid</li> <li>Clone your fork</li> <li>Install PDM</li> <li>Install dependencies in virtual environment</li> <li>Configure pre-commit</li> <li>Make your changes!</li> </ol>"},{"location":"contributing/#detailed-guide","title":"Detailed guide","text":""},{"location":"contributing/#create-a-fork-and-clone-the-repo","title":"Create a fork and clone the repo","text":"<p>First of all, you will need to create a fork.</p> <p>Clone it and <code>cd</code> into the directory:</p> <pre><code>git clone https://github.com/__your_username__/repid.git\ncd repid\n</code></pre>"},{"location":"contributing/#pdm-venv","title":"PDM &amp; venv","text":"<p>Repid uses PDM to manage virtual environment, dependencies &amp; package the project.</p> <p>Tip</p> <p>Use <code>brew</code> or <code>pipx</code> when installing PDM to keep your system Python clean.</p> <pre><code>brew install pdm\n</code></pre> <pre><code>pipx install pdm\n</code></pre> <p>After installation is done, run the following command in the project's root directory:</p> <pre><code>pdm install --group :all\n</code></pre> <p>It will create virtual environment and install inside of it all dependencies, including those, which are needed for development.</p> <p>Important</p> <p>Use lowest supported by <code>repid</code> version of Python (== 3.8 for now) for your venv.</p> <p>You can use pyenv to set up multiple versions of Python on your system.</p> <p>To activate a venv run:</p> <pre><code>$(pdm venv activate)\n</code></pre> <p>...or simply execute the needed command with <code>pdm run</code> prefix, e.g.</p> <pre><code>pdm run mkdocs serve\n</code></pre>"},{"location":"contributing/#pre-commit","title":"pre-commit","text":"<p><code>repid</code> uses pre-commit to run linters and formatters. To initialize <code>pre-commit</code> run:</p> <pre><code>pdm run pre-commit install --install-hooks\n</code></pre> <p>If you want to run all linters and formatters, execute the following command:</p> <pre><code>pdm run pre-commit run -a\n</code></pre> <p>If you want to commit some changes disregarding pre-commit hooks, add <code>-n</code> or <code>--no-verify</code> flag to <code>git commit</code> command.</p> <p>Important</p> <p>Keep in mind that when you will submit your pull request, all the hooks must pass in CI anyway, or, unfortunately, we will have to decline your contribution.</p>"},{"location":"contributing/#make-your-changes","title":"Make your changes","text":"<p>Make your changes, create commits and submit a pull request.</p> <p>Here are some advices:</p> <ol> <li> <p>Commits:</p> <ul> <li>Please use gitmoji to prefix your commit messages</li> <li>Try to make commits atomic</li> <li>gitmoji should describe type of the change, while commit message shows the exact change in behavior, e.g.</li> </ul> <pre><code>\u267b\ufe0f Refactored _signal_emitter property and wrapping in new into a separate _WrapperABC class\n</code></pre> </li> <li> <p>Issues:</p> <ul> <li>Please use one of provided templates to create an issue</li> <li>Make it as much descriptive as possible</li> </ul> </li> <li> <p>Pull requests:</p> <ul> <li>If your pull request isn't very simple (like fixing a typo in the docs) - please create an issue first, so we can discuss it</li> <li>Mark pull request as a resolver for the related issue(-s)</li> <li>Please complete the checklist provided in the pull request template</li> <li>Please avoid creating very large pull requests</li> </ul> </li> </ol>"},{"location":"contributing/#running-tests-locally","title":"Running tests locally","text":"<p>You will need docker to run tests locally.</p> <p>Apart from that, everything is automated via pytest (including creation of containers for integration testing!), so all you need to do is:</p> <pre><code>pdm run pytest\n</code></pre>"},{"location":"contributing/#vscode-and-dev-container","title":"VSCode and Dev Container","text":"<p>If you are willing to use VSCode, repid comes with some configs already in place. Feel free to modify them up to your liking, but be careful not to commit any changes unintentionally.</p> <p>Another quality-of-life feature is Dev Container. Essentially it is a bunch of configs, which describe how to create a docker container, that comes with VSCode server, all the necessary plugins and a virtual environment already set up. You can use it with GitHub Codespaces to create it in one click and start developing right away!</p>"},{"location":"features/","title":"Features","text":""},{"location":"features/#message-protocols-abstraction","title":"Message protocols abstraction","text":"<p>One of the key features of Repid is its message protocols abstraction layer, which allows developers to work with message brokers without worrying about the underlying implementation details. Not only this makes it easy for developers to quickly create applications that use various message brokers to communicate with other systems and services, but it also ensures ease of integration with those brokers, which are not supported out-of-the-box.</p>"},{"location":"features/#application-level-routing","title":"Application level routing","text":"<p>Repid provides a robust application level routing system that allows developers to easily define and handle different routes within their application. This allows developers to build complex applications that can route different requests, even if they are coming from one queue. You don't have to rely on broker to support routing anymore!</p>"},{"location":"features/#asyncio-top-to-bottom","title":"asyncio top-to-bottom","text":"<p>Another key feature of Repid is that it uses asyncio everywhere: from broker level to execution of your function. This allows developers to build highly concurrent applications that can take advantage of the performance benefits of asyncio. But don't worry - synchronous code is still possible to run!</p>"},{"location":"features/#flexible","title":"Flexible","text":"<p>Repid provides you with sensible defaults, but it's okay to disagree! The framework allows you to change some of it's core functions, such as data structures (and their encoding/decoding mechanisms), function argument mapper and validator, input serializer and more.</p>"},{"location":"features/#middlewares","title":"Middlewares","text":"<p>Repid includes support for middlewares, which are functions that can be used to extend the functionality of an application. You can use middlewares to add, for example, custom logging to your application.</p>"},{"location":"quickstart_guide/","title":"Quickstart Guide","text":""},{"location":"quickstart_guide/#before-we-start","title":"Before we start","text":"<p>To follow this guide you will need a virtual environment with <code>repid</code> installed. We will use dummy brokers, but feel free to exchange those for any other ones - it should just work.</p>"},{"location":"quickstart_guide/#consumer","title":"Consumer","text":"<p>Let's start by creating a simple pseudo-async function that counts length of a string:</p> <pre><code>import asyncio\nasync def string_length(the_string: str) -&gt; int:\nawait asyncio.sleep(1)\nprint(the_string)\nreturn len(the_string)\n</code></pre> <p>Now, we have to create a router for <code>repid</code> to know, that <code>string_length</code> actor exists.</p> <pre><code>import asyncio\nimport repid\nrouter = repid.Router()\n@router.actor\nasync def string_length(the_string: str) -&gt; int:\nawait asyncio.sleep(1)\nprint(the_string)\nreturn len(the_string)\n</code></pre> <p>Aaand let's finish our application with specifying connection and creating a worker.</p> <pre><code>import asyncio\nimport repid\napp = repid.Repid(repid.Connection(repid.DummyMessageBroker()))  # (1)\nrouter = repid.Router()\n@router.actor\nasync def string_length(the_string: str) -&gt; int:\nawait asyncio.sleep(1)\nprint(the_string)\nreturn len(the_string)\nasync def main() -&gt; None:  # (2)\nasync with app.magic():  # (3)\nworker = repid.Worker(routers=[router])  # (4)\nawait worker.run()  # (5)\nif __name__ == \"__main__\":\nasyncio.run(main())\n</code></pre> <ol> <li>Create a <code>repid</code> app with the dummy message broker.</li> <li>The main function, which will execute our async code.</li> <li>Inside of this context manager every object will be provided with the connection that is attached to the <code>repid</code> app which we've created.</li> <li>Create an instance of a worker. Don't forget to specify our router!</li> <li>Run the worker until it receives a <code>SIGINT</code> ( Ctrl+C ) or a <code>SIGTERM</code>.</li> </ol>"},{"location":"quickstart_guide/#producer","title":"Producer","text":"<p>Let's enqueue a job!</p> example.py<pre><code>import asyncio\nimport repid\napp = repid.Repid(repid.Connection(repid.DummyMessageBroker()))\nrouter = repid.Router()\n@router.actor\nasync def string_length(the_string: str) -&gt; int:\nawait asyncio.sleep(1)\nprint(the_string)\nreturn len(the_string)\nasync def main() -&gt; None:\nasync with app.magic():\nhello_job = repid.Job(\n\"string_length\",  # (1)\nargs=dict(the_string=\"Hello world!\"),  # (2)\n)\nawait hello_job.queue.declare()  # (3)\nawait hello_job.enqueue()\nworker = repid.Worker(routers=[router])\nawait worker.run()\nif __name__ == \"__main__\":\nasyncio.run(main())\n</code></pre> <ol> <li>Name of the job will be used to route it to the similarly named actor.</li> <li>Using dictionary to map arguments' names to values. The dictionary will be encoded with <code>orjson</code> by default.</li> <li>You only need to declare a queue once. Ideally you would do that on application startup.</li> </ol> <p>This will enqueue a job to the default queue, which than worker will consume &amp; route to the <code>string_length</code> function with argument <code>the_string</code> set to <code>\"Hello world!\"</code>.</p> <p>After running the script, you should receive:</p> <pre><code>$ python example.py\n\nHello world!\n</code></pre>"},{"location":"user_guide/deferred_scheduling/","title":"Deferred scheduling","text":"<p>You can create a job with delayed and recurring execution. Let's focus on the options in the next sections.</p>"},{"location":"user_guide/deferred_scheduling/#delayed-execution","title":"Delayed execution","text":"<p>To delay the execution of a Job, specify <code>deferred_until</code> argument.</p> <pre><code>from datetime import datetime\nfrom repid import Job\n# code above is omitted\nJob(\"delayed_job\", deferred_until=datetime(2077, 1, 1))  # (1)\n# code below is omitted\n</code></pre> <ol> <li>The job will be executed on the 1st of January in 2077.</li> </ol>"},{"location":"user_guide/deferred_scheduling/#recurring-execution","title":"Recurring execution","text":"<p>Warning</p> <p>Next execution time for a recurring job is set after the previous execution. Therefore, if a job wasn't processed or processing took longer than recurring time frame, next execution will be set to the next earliest time.</p>"},{"location":"user_guide/deferred_scheduling/#defer-by","title":"Defer by","text":"<p>If you want a job to be executed every equal period of time (e.g. every 10 minutes, every 2 days, etc.) you can specify <code>deferred_by</code> argument.</p> <pre><code>from datetime import timedelta\nfrom repid import Job\n# code above is omitted\nJob(\"every_2_days\", deferred_by=timedelta(days=2))\n# code below is omitted\n</code></pre>"},{"location":"user_guide/deferred_scheduling/#cron","title":"cron","text":"<p>If you want to specify a job with recurring execution in cron format, you will have to install repid with additional flag as follows:</p> <pre><code>pip install repid[cron]\n</code></pre> <p>It will install croniter package, which will be used internally to calculate next time of an execution.</p> <p>You can specify any cron string supported by croniter using <code>cron</code> argument of a Job.</p> <pre><code>from repid import Job\n# code above is omitted\nJob(\"every_day_at_noon\", cron=\"0 12 * * *\")\n# code below is omitted\n</code></pre>"},{"location":"user_guide/deferred_scheduling/#rescheduling-and-retries","title":"Rescheduling and retries","text":"<p>Rescheduling for a retry will take precedence over rescheduling for the next recurring iteration.</p> <p>Keep in mind, that depending on the way how your retries are set up, some recurring iterations might be skipped.</p> <p>If the number of retries was exceeded the job will be rescheduled for the next recurring iteration anyway.</p>"},{"location":"user_guide/deferred_scheduling/#combining","title":"Combining","text":"<p>Combining <code>deferred_by</code> and <code>cron</code> in one job is prohibited.</p> <p>Combining <code>deferred_until</code> with either <code>deferred_by</code> or <code>cron</code> will delay the first execution until <code>deferred_until</code> and recurrently continue using <code>deferred_by</code> or <code>cron</code>.</p>"},{"location":"user_guide/deferred_scheduling/#time-to-live","title":"Time-to-live","text":"<p>You can narrow the time of message consumption window using <code>ttl</code> argument. It will ensure that since latest scheduling hasn't passed any more time. If not, the message will be marked as 'not acknowledged' and put in a dead-letter queue.</p> <pre><code>from datetime import timedelta\nfrom repid import Job\n# code above is omitted\nJob(\"consume_me_faster_than_3_days\", ttl=timedelta(days=3))\n# code below is omitted\n</code></pre> <p>Note</p> <p>Every rescheduling of a Job resets time-to-live timer. Time of rescheduling will be considered the new starting point.</p>"},{"location":"user_guide/deferred_scheduling/#recap","title":"Recap","text":"<ol> <li>Delay job's execution using <code>deferred_until</code></li> <li>Create a recurring job using <code>deferred_by</code> or <code>cron</code></li> <li>Set <code>ttl</code> to ensure fast enough consumption</li> </ol>"},{"location":"user_guide/initial_setup/","title":"Initial setup","text":""},{"location":"user_guide/initial_setup/#app-structure","title":"App structure","text":"<p>Usually repid apps are split up in two parts: producer (the one, who enqueues/creates new jobs) and consumer (the one who actually does all the heavy lifting).</p> <p>The framework is intentionally designed to separate those two parts and you may even have them in different codebases.</p> <p>With that said, for simplicity, most of the examples in docs are using <code>DummyMessageBroker</code>, which requires both sides to be run in one process.</p>"},{"location":"user_guide/initial_setup/#brokers","title":"Brokers","text":"<p>First of all you will have to establish a connection using one of broker implementations.</p> <p>Repid provides some brokers (RabbitMQ, Redis, etc.) out-of-the-box, but you will have to specify extra dependencies for them to work:</p> <p>For RabbitMQ install</p> <pre><code>pip install repid[amqp]\n</code></pre> <p>For Redis install</p> <pre><code>pip install repid[redis]\n</code></pre> <p>Mostly for test purposes, repid also provides <code>DummyMessageBroker</code> &amp; <code>DummyBucketBroker</code>, which are using RAM to store data, thus requiring your app to run in one context/process/etc. You don't need any extra dependencies to use those.</p> <p>Different brokers may have different initialization parameters, but often the pattern is to simply pass a connection string. Bucket brokers may also have some way of specifying whether they are supposed to be used to store results or not. This will come in handy later.</p> <p>Let's suppose we want to use <code>RabbitMessageBroker</code>, so after we've installed the necessary dependencies, you may write something like this:</p> <pre><code>import os\nfrom repid import RabbitMessageBroker\nmy_broker = RabbitMessageBroker(dsn=os.environ.get(\"RABBIT_CONNECTION_STRING\"))\n</code></pre>"},{"location":"user_guide/initial_setup/#connection","title":"Connection","text":"<p>After creating a broker instance you will have to create a <code>Connection</code>. Connection is a data structure which will tie your message broker, bucker broker, result bucket broker &amp; middleware.</p> <p>Upon creation of a <code>Connection</code>, it will create a new <code>Middleware</code> instance and assign it to supplied brokers. Thus, calling a broker before it was assigned a middleware won't call any middleware functions.</p> <p>Each <code>Connection</code> instance has <code>is_open</code> boolean flag. This flag is only updated when connection instance itself is changing state (== using <code>connect</code> &amp; <code>disconnect</code> methods).</p> <p>Warning</p> <p><code>is_open</code> flag doesn't track state of underlying broker connections. <code>Connection</code> class is not responsible for reconnection in case of a failure.</p> <p>Using our previous example with <code>RabbitMessageBroker</code>, let's create a <code>Connection</code>:</p> <pre><code>import os\nfrom repid import Connection, RabbitMessageBroker\nmy_broker = RabbitMessageBroker(dsn=os.environ.get(\"RABBIT_CONNECTION_STRING\"))\nmy_connection = Connection(my_broker)\n</code></pre> <p>Or here is another example with bucket brokers also specified:</p> <pre><code>import os\nfrom repid import Connection, RabbitMessageBroker, RedisBucketBroker\nmy_connection = Connection(\nmessage_broker=RabbitMessageBroker(dsn=os.environ.get(\"RABBIT_CONNECTION_STRING\")),\nargs_bucket_broker=RedisBucketBroker(dsn=os.environ.get(\"REDIS_ARGS_CONNECTION_STRING\")),\nresults_bucket_broker=RedisBucketBroker(\ndsn=os.environ.get(\"REDIS_RESULT_CONNECTION_STRING\"),\nuse_result_bucket=True,\n),\n)\n</code></pre>"},{"location":"user_guide/initial_setup/#magic","title":"Magic","text":"<p>...or not really </p> <p>So now you have this connection instance, but you would need to provide it to every object manually. To avoid doing so, create a <code>Repid</code> instance and provide connection to it. Then you will be able to use <code>magic</code> async context manager, which will automatically bind your connection to the needed objects.</p> <pre><code>from repid import Repid, Job\n# `my_connection` definition is omitted\napp = Repid(my_connection)\nasync def main() -&gt; None:\nasync with app.magic():\nj = Job(\"my_awesome_job\")  # (1)\nawait j.enqueue()\n# `main` function call is omitted\n</code></pre> <ol> <li>You don't have to supply <code>_connection</code> argument to the <code>Job</code>, it's done auto-magically</li> </ol> <p>If you want more control over the magic, you can use <code>magic_connect</code> &amp; <code>magic_disconnect</code>. So here is how you can use it with <code>FastAPI</code>:</p> <pre><code>from fastapi import FastAPI\nfrom repid import Repid, Job\n# `my_connection` definition is omitted\nrepid_app = Repid(my_connection)\nfastapi_app = FastAPI()\n@fastapi_app.on_event(\"startup\")\nasync def open_repid_connection() -&gt; None:\nawait repid_app.magic_connect()\n@fastapi_app.on_event(\"shutdown\")\nasync def close_repid_connection() -&gt; None:\nawait repid_app.magic_disconnect()\n@fastapi_app.post(\"/create-job\")\nasync def create_job() -&gt; None:\nawait Job(\"my_awesome_fastapi_job\").enqueue()  # (1)\n</code></pre> <ol> <li>Again, you don't have to supply <code>_connection</code> argument to the <code>Job</code>, as long as <code>magic_connect</code> was called before.</li> </ol>"},{"location":"user_guide/initial_setup/#but-how-does-it-work","title":"...but how does it work?","text":"<p>Internally, <code>Repid</code> class (not to be confused with instances of the <code>Repid</code> class) holds a thread-local variable, which is used to store <code>Connection</code> object. It also calls <code>connect</code>/<code>disconnect</code> method so you don't have to!</p> <p>Warning</p> <p>Keep in mind that as connections are meant to be long-lived</p> <pre><code>async with app.magic()\n...\n</code></pre> <p>doesn't close connection on exit by default!</p> <p>To close the connection, set <code>auto_disconnect</code> flag to True</p> <pre><code>async with app.magic(auto_disconnect=True)\n...\n</code></pre>"},{"location":"user_guide/initial_setup/#recap","title":"Recap","text":"<ol> <li>Create a broker</li> <li>Submit it to a <code>Connection</code></li> <li>Add it to <code>Repid</code> to get the magic</li> <li>Use it!</li> </ol> <pre><code>import asyncio\nimport os\nfrom repid import Connection, Job, RabbitMessageBroker, RedisBucketBroker, Repid\napp = Repid(\nConnection(\nmessage_broker=RabbitMessageBroker(dsn=os.environ.get(\"RABBIT_CONNECTION_STRING\")),\nargs_bucket_broker=RedisBucketBroker(dsn=os.environ.get(\"REDIS_ARGS_CONNECTION_STRING\")),\nresults_bucket_broker=RedisBucketBroker(\ndsn=os.environ.get(\"REDIS_RESULT_CONNECTION_STRING\"),\nuse_result_bucket=True,\n),\n)\n)\nasync def main() -&gt; None:\nasync with app.magic():\nawait Job(\"my_awesome_job\").enqueue()\nif __name__ == \"__main__\":\nasyncio.run(main())\n</code></pre>"},{"location":"user_guide/jobs_actors_and_workers/","title":"Jobs, Actors and Workers","text":"<p>Now, that you now how to properly set up a connection, let's focus on creation of jobs and their processing.</p>"},{"location":"user_guide/jobs_actors_and_workers/#jobs","title":"Jobs","text":"<p>Job is a data structure, which describes what and how you want to be executed.</p> <p>As you may want the execution to be periodic or to be retried in case of a failure, 1 job doesn't necessarily translate to 1 message on the broker's side.</p> <p>The only required parameter of a Job is <code>name</code>. It specifies what <code>actor</code> has to be called on the consumer side. Routing is done on application level.</p>"},{"location":"user_guide/jobs_actors_and_workers/#simple-job","title":"Simple job","text":"<p>It's extremely easy to create a job:</p> <pre><code>import asyncio\nfrom repid import Connection, DummyMessageBroker, Job, Repid\napp = Repid(Connection(DummyMessageBroker()))\nasync def main() -&gt; None:\nasync with app.magic():\nJob(name=\"my_awesome_job\")\nif __name__ == \"__main__\":\nasyncio.run(main())\n</code></pre>"},{"location":"user_guide/jobs_actors_and_workers/#jobs-and-queues","title":"Jobs and queues","text":"<p>To schedule an execution of a job, you have to call <code>enqueue</code> method...</p> <pre><code># code above is omitted\nasync with app.magic():\nj = Job(name=\"my_awesome_job\")\nawait j.enqueue()  # \ud83d\udca5 KeyError: 'default'\n# code below is omitted\n</code></pre> <p>...but it will fail, because we haven't initialized the default queue. Let's fix it:</p> <pre><code># code above is omitted\nasync with app.magic():\nj = Job(name=\"my_awesome_job\")  # (1)\nawait j.queue.declare()\nawait j.enqueue()\n# \u2705 Success!\n# code below is omitted\n</code></pre> <ol> <li>By default queue is set to <code>Queue(name=\"default\")</code></li> </ol> <p>You may also want to initialize queue(-s) preemptively, in, e.g., <code>setup</code> function.</p> <pre><code>from repid import Queue\n# code above is omitted\nasync def setup() -&gt; None:\nasync with app.magic():\nawait Queue().declare()  # (1)\nawait Queue(name=\"my_awesome_queue\").declare()\n# code below is omitted\n</code></pre> <ol> <li>Will declare a queue with name set to <code>default</code></li> </ol> <p>Tip</p> <p>Usually brokers support multiple queue declarations (== re-declaring already existing queue will have no effect), meaning that you can declare a queue on every app startup to ensure correct workflow of your application.</p> <p>You can specify <code>queue</code> argument either as a string or as a <code>Queue</code> object. In case of a string it will be automatically converted to a <code>Queue</code> object during <code>Job</code> object initialization.</p> <pre><code>my_awesome_job = Job(name=\"my_awesome_job\", queue=\"non-default-queue\")\nanother_job = Job(name=\"another_job\", queue=Queue(\"another-queue\"))\nprint(type(my_awesome_job.queue))  # repid.Queue\nprint(type(another_job.queue))  # repid.Queue\n</code></pre>"},{"location":"user_guide/jobs_actors_and_workers/#job-priority","title":"Job priority","text":"<p>You can specify priority of the job using <code>PrioritiesT</code> enum. Default is set to <code>PrioritiesT.MEDIUM</code>. <code>HIGH</code>, <code>MEDIUM</code> &amp; <code>LOW</code> levels are officially supported.</p> <pre><code>from repid import Job, PrioritiesT\n# code above is omitted\nJob(\"awesome_job_with_priority\", priority=PrioritiesT.HIGH)\n# code below is omitted\n</code></pre>"},{"location":"user_guide/jobs_actors_and_workers/#job-id-and-uniqueness","title":"Job id and uniqueness","text":"<p>By default Job doesn't have any id and on every <code>enqueue</code> call a message will be generated a new id using <code>uuid.uuid4().hex</code>. Therefore, by default, a Job isn't considered unique.</p> <p>You can check it with <code>is_unique</code> flag.</p> <pre><code>print(Job(\"non_unique_job\").is_unique)  # False\n</code></pre> <p>If you specify <code>id_</code> argument - it will not be regenerated on every call of <code>enqueue</code> and therefore the Job is considered unique.</p> <pre><code>print(Job(\"unique_job\", id_=\"my_unique_id\").is_unique)  # True\n</code></pre> <p>Warning</p> <p>Some, although not all, brokers are ensuring that there are no messages with the same id in the queue.</p>"},{"location":"user_guide/jobs_actors_and_workers/#retries","title":"Retries","text":"<p>If you want a Job to be retried in case of a failure during the execution - specify <code>retries</code> argument. Default is set to <code>1</code>, which means that the Job will only be tried once and put in a dead-letter queue in case of a failure.</p> <pre><code>Job(\"retryable_job\", retries=3)\n</code></pre>"},{"location":"user_guide/jobs_actors_and_workers/#timeout","title":"Timeout","text":"<p>You can also specify maximum allowed execution time for a Job using <code>timeout</code> argument. Default is set to <code>10 minutes</code>.</p> <pre><code>from datetime import timedelta\n# code above is omitted\nJob(\"very_fast_job\", timeout=timedelta(seconds=5))\nJob(\"very_slow_job\", timeout=timedelta(hours=2))\n# code below is omitted\n</code></pre> <p>Execution timeout is also a valid reason for a retry.</p> <p>Tip</p> <p>You should sensibly limit Job's timeout, as it can be a deciding factor for rescheduling in case of a worker disconnection.</p>"},{"location":"user_guide/jobs_actors_and_workers/#actors","title":"Actors","text":"<p>Actors are functions, which are meant to be executed when a worker (== consumer) receives a message.</p> <p>To create an actor you first have to create a <code>Router</code> and then use <code>Router.actor</code> as a decorator for your function.</p> <pre><code>from repid import Router\nmy_router = Router()\n@my_router.actor\nasync def my_awesome_function() -&gt; None:\nprint(\"Hello Repid!\")\n</code></pre> <p>Note</p> <p>Actor decorator does not anyhow change the decorated function. The initial function remains callable as it was before.</p>"},{"location":"user_guide/jobs_actors_and_workers/#actor-name","title":"Actor name","text":"<p>By default, name of an actor is the same as the name of the function. You can override it with <code>name</code> argument.</p> <pre><code>from repid import Router\nmy_router = Router()\n@my_router.actor(name=\"another_name\")\nasync def my_awesome_function() -&gt; None:\nprint(\"Hello Repid!\")\n</code></pre>"},{"location":"user_guide/jobs_actors_and_workers/#actor-queue","title":"Actor queue","text":"<p>You can also specify what queue should actor listen on using <code>queue</code> argument.</p> <pre><code>@my_router.actor(queue=\"another_queue\")\nasync def my_awesome_function() -&gt; None:\n...\n</code></pre>"},{"location":"user_guide/jobs_actors_and_workers/#thread-vs-process","title":"Thread vs Process","text":"<p>If your function is synchronous, you can specify if you want it to be run in a separate process instead of a thread by setting <code>run_in_process</code> to True.</p> <pre><code>@my_router.actor(run_in_process=True)\ndef my_synchronous_function() -&gt; None:\n...\n</code></pre>"},{"location":"user_guide/jobs_actors_and_workers/#retry-policy","title":"Retry Policy","text":"<p>In case of a retry, application will reschedule the message with a delay. The delay is calculated using a retry policy, which defaults to exponential. You can override the behavior with <code>retry_policy</code> argument.</p> <pre><code>from repid import Router, default_retry_policy_factory\nmy_router = Router()\n@my_router.actor(\nretry_policy=default_retry_policy_factory(\nmin_backoff=60,\nmax_backoff=86400,\nmultiplier=5,\nmax_exponent=15,\n)\n)\nasync def my_exceptional_function() -&gt; None:\nraise Exception(\"Some random exception.\")\n</code></pre> <p>...or you can use practically any function, which confirms to <code>RetryPolicyT</code>.</p> <pre><code>from repid import Router\nmy_router = Router()\n@my_router.actor(retry_policy=lambda retry_number=1: retry_number * 100)\nasync def my_exceptional_function() -&gt; None:\nraise Exception(\"Some random exception.\")\n</code></pre>"},{"location":"user_guide/jobs_actors_and_workers/#workers","title":"Workers","text":"<p>Workers are controllers, which are responsible for receiving messages and executing related actors.</p>"},{"location":"user_guide/jobs_actors_and_workers/#workers-and-routers","title":"Workers and Routers","text":"<p>Workers are also routers. You can assign actors directly to them.</p> <pre><code>import asyncio\nfrom repid import Connection, DummyMessageBroker, Job, Repid, Worker\napp = Repid(Connection(DummyMessageBroker()))\nasync def main() -&gt; None:\nasync with app.magic():\nmy_worker = Worker()\n@my_worker.actor\nasync def my_func() -&gt; None:\nprint(\"Hello!\")\nif __name__ == \"__main__\":\nasyncio.run(main())\n</code></pre> <p>You can include actors from other routers into a worker.</p> <p>Warning</p> <p>Adding actor with already existing name will override previously stored actor.</p> <pre><code>router = Router()\nother_router = Router()\n# code above is omitted\nWorker(routers=[router, other_router])\n# or\nmy_worker = Worker()\nmy_worker.include_router(router)\nmy_worker.include_router(other_router)\n# code below is omitted\n</code></pre>"},{"location":"user_guide/jobs_actors_and_workers/#running-a-worker","title":"Running a Worker","text":"<p>To run a worker simply call <code>run</code> method. The worker will be running until it receives a signal (<code>SIGINT</code> or <code>SIGTERM</code>, by default) or until it reaches <code>messages_limit</code>, which by default is set to infinity.</p> <p>Tip</p> <p>Worker will declare all queues that it's aware about (via assigned actors) on the execution of <code>run</code> method. To override this behavior set <code>auto_declare</code> flag to False.</p> <pre><code>import asyncio\nfrom repid import Connection, DummyMessageBroker, Repid, Worker\napp = Repid(Connection(DummyMessageBroker()))\nasync def main() -&gt; None:\nasync with app.magic(auto_disconnect=True):\nmy_worker = Worker()\nawait my_worker.run()\nif __name__ == \"__main__\":\nasyncio.run(main())\n</code></pre> <p>After worker receives a signal it will attempt a graceful shutdown. It means that it will stop receiving new messages and wait for <code>gracefull_shutdown_time</code> (default: 25 seconds) to let already running actors complete.</p> <p>Note</p> <p>Default <code>gracefull_shutdown_time</code> is set to 25 seconds because default Kubernetes timeout after sending <code>SIGTERM</code> and before sending <code>SIGKILL</code> is set to 30 seconds. 5 second buffer is provided to ensure that every uncompleted task will be rejected before ungraceful termination.</p> <p>Any actor which exceeds that period will be forced to stop and corresponding message will be rejected, meaning that the message broker will be responsible for requeueing the message and retry counter will not be increased.</p> <pre><code>from signal import SIGQUIT\n# code above is omitted\nWorker(\ngracefull_shutdown_time=100.0,  # seconds\nmessages_limit=10_000,\nhandle_signals=[SIGQUIT],\n)\n# code below is omitted\n</code></pre> <p>After Worker is done running, it will return an internal <code>_Runner</code> object, which you can use to retrieve information about amount of actor runs.</p> <pre><code>import asyncio\nfrom repid import Connection, DummyMessageBroker, Repid, Worker\napp = Repid(Connection(DummyMessageBroker()))\nasync def main() -&gt; None:\nasync with app.magic(auto_disconnect=True):\nmy_worker = Worker()\nrunner = await my_worker.run()\nprint(f\"Total actor runs: {runner.processed}\")\nif __name__ == \"__main__\":\nasyncio.run(main())\n</code></pre>"},{"location":"user_guide/jobs_actors_and_workers/#recap","title":"Recap","text":"<ol> <li>Declare a <code>Queue</code> and enqueue a <code>Job</code></li> <li>Create an <code>Actor</code></li> <li>Assign it to a <code>Worker</code> directly or via a <code>Router</code></li> <li>Run the <code>Worker</code></li> </ol> <pre><code>import asyncio\nimport repid\napp = repid.Repid(repid.Connection(repid.DummyMessageBroker()))\nrouter = repid.Router()\n@router.actor\nasync def awesome_hello() -&gt; None:\nprint(\"Hello from an actor!\")\nasync def producer_side() -&gt; None:\nasync with app.magic():\nawait repid.Queue().declare()\nawait repid.Job(\"awesome_hello\").enqueue()\nasync def consumer_side() -&gt; None:\nasync with app.magic(auto_disconnect=True):\nawait repid.Worker(routers=[router], messages_limit=1).run()\nasync def main() -&gt; None:\nawait producer_side()\nawait consumer_side()\nif __name__ == \"__main__\":\nasyncio.run(main())\n</code></pre>"}]}